{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2uYlGuJPLSX"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7bhEpnLPLSa"
   },
   "source": [
    "# Lab 3.1.1 \n",
    "# *Data Wrangling and Munging with Pandas*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2GEOE8QPLSc"
   },
   "source": [
    "## Part 1: Wrangling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ny8KO6sjPLSd"
   },
   "source": [
    "The term \"data wrangling\" is analogous to capturing wild horses and getting them into a fenced area; the horses are data and the fencing is your computer. The more common data wrangling tasks include:\n",
    "\n",
    "- reading flat files\n",
    "- reading Excel files\n",
    "- downloading from web pages\n",
    "  - csv\n",
    "  - html\n",
    "  - json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebAgCSWKPLSf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSQPEJFUPLSk"
   },
   "source": [
    "*It is good practice to display the library version numbers for future reference:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gme7oqSGPLSl",
    "outputId": "f8b97721-2f39-4701-a73c-56bd79e92191"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy:  1.16.4\n",
      "Pandas:  0.24.2\n"
     ]
    }
   ],
   "source": [
    "print('Numpy: ', np.__version__)\n",
    "print('Pandas: ', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s97YhdU6PLSp"
   },
   "source": [
    "### CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nA6wV0cOPLSr"
   },
   "source": [
    "Below are three attempts to load the file \"bikeshare.csv\" into a DataFrame named `bikes`. Why are they wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bKWJInTWumG",
    "outputId": "3db71f8d-ad09-4583-a975-8e0e0ad70772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0\n",
      "0  instant,dteday,season,yr,mnth,hr,holiday,weekd...\n",
      "1  1,2011-01-01,1,0,1,0,0,6,0,1,0.24,0.2879,0.81,...\n",
      "2  2,2011-01-01,1,0,1,1,0,6,0,1,0.22,0.2727,0.8,0...\n",
      "3  3,2011-01-01,1,0,1,2,0,6,0,1,0.22,0.2727,0.8,0...\n",
      "4  4,2011-01-01,1,0,1,3,0,6,0,1,0.24,0.2879,0.75,...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ck_ra\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# wrong:\n",
    "bikes = pd.read_table('../../../DATA/bikeshare.csv', header = None)\n",
    "print(bikes.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEhygWXsPLSs",
    "outputId": "1ba0b698-2a30-47bc-da8c-691313083a20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0\n",
      "0  instant,dteday,season,yr,mnth,hr,holiday,weekd...\n",
      "1  1,2011-01-01,1,0,1,0,0,6,0,1,0.24,0.2879,0.81,...\n",
      "2  2,2011-01-01,1,0,1,1,0,6,0,1,0.22,0.2727,0.8,0...\n",
      "3  3,2011-01-01,1,0,1,2,0,6,0,1,0.22,0.2727,0.8,0...\n",
      "4  4,2011-01-01,1,0,1,3,0,6,0,1,0.24,0.2879,0.75,...\n",
      "\n",
      "  1,2011-01-01,1,0,1,0,0,6,0,1,0.24,0.2879,0.81,0,3,13,16\n",
      "0  2,2011-01-01,1,0,1,1,0,6,0,1,0.22,0.2727,0.8,0...     \n",
      "1  3,2011-01-01,1,0,1,2,0,6,0,1,0.22,0.2727,0.8,0...     \n",
      "2  4,2011-01-01,1,0,1,3,0,6,0,1,0.24,0.2879,0.75,...     \n",
      "3  5,2011-01-01,1,0,1,4,0,6,0,1,0.24,0.2879,0.75,...     \n",
      "4  6,2011-01-01,1,0,1,5,0,6,0,2,0.24,0.2576,0.75,...     \n",
      "\n",
      "  instant,dteday,season,yr,mnth,hr,holiday,weekday,workingday,weathersit,temp,atemp,hum,windspeed,casual,registered,cnt\n",
      "0  1,2011-01-01,1,0,1,0,0,6,0,1,0.24,0.2879,0.81,...                                                                   \n",
      "1  2,2011-01-01,1,0,1,1,0,6,0,1,0.22,0.2727,0.8,0...                                                                   \n",
      "2  3,2011-01-01,1,0,1,2,0,6,0,1,0.22,0.2727,0.8,0...                                                                   \n",
      "3  4,2011-01-01,1,0,1,3,0,6,0,1,0.24,0.2879,0.75,...                                                                   \n",
      "4  5,2011-01-01,1,0,1,4,0,6,0,1,0.24,0.2879,0.75,...                                                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ck_ra\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \n",
      "C:\\Users\\ck_ra\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  import sys\n",
      "C:\\Users\\ck_ra\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# wrong:\n",
    "bikes = pd.read_table('../../../DATA/bikeshare.csv', header = None)\n",
    "print(bikes.head())\n",
    "print()\n",
    "\n",
    "# wrong:\n",
    "bikes = pd.read_table('../../../DATA/bikeshare.csv', header = 1)\n",
    "print(bikes.head())\n",
    "print()\n",
    "\n",
    "# wrong:\n",
    "bikes = pd.read_table('../../../DATA/bikeshare.csv', header = 0)\n",
    "print(bikes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSi1DxxMPLSx"
   },
   "source": [
    "?:\n",
    "\n",
    "> Indented block\n",
    "\n",
    "\n",
    "ANSWER: Case 1 treats headings as just another data row. Case 2 treats the 1st data row as the column header. Case 3 gets the header right (row 0), but reads each row as a single column (Nb. the other two make that same mistake). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8F91d55PLSz"
   },
   "source": [
    "Load the file \"bikeshare.csv\" into a DataFrame named `bikes`, and confirm that it was loaded properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LN5xo5zPLS0",
    "outputId": "b901c614-d42a-40c0-d482-6fd280d3bb6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
      "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
      "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
      "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
      "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
      "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
      "\n",
      "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
      "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
      "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
      "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
      "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
      "4           1  0.24  0.2879  0.75        0.0       0           1    1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ck_ra\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#ANSWER:\n",
    "bikes = pd.read_table('../../../DATA/bikeshare.csv', header = 0, sep = ',')\n",
    "print(bikes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddiw5n-GPLS4"
   },
   "source": [
    "Note that we could have used `read.csv()` above. When is `read_table()` necessary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3vwhAEyPLS5"
   },
   "source": [
    "?:\n",
    "ANSWER: When `sep` is not the comma character, or we need fine control that `read.csv()` does not provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnfdJfglPLS6"
   },
   "source": [
    "Flat files can be full of surprises. Here are some issues to watch out for:\n",
    "\n",
    "- separator character is something other than the comma\n",
    "  - \";\", \"|\", and tab are popular\n",
    "- newline character is something other than what the O/S expects \n",
    "  - Tip: Don't hard-code the character codes for carriage returns, linefeeds, etc. Use Python's built-in representation instead (e.g. Python translates \"\\n\" to the newline character and \"\\t\" to the tab character on any O/S).\n",
    "- truncated lines\n",
    "  - if there are empty fields at the end of a line it is possible that their separators will be missing, resulting in a \"jagged\" file\n",
    "- embedded commas or quotes\n",
    "  - a free-text field containing embedded commas may split into separate fields on input\n",
    "  - a free-text field containing embedded quotes may not parse correctly\n",
    "- unescaped characters\n",
    "  - the \"\\\" character indicates a control code to Python, which will break the I/O\n",
    "    - e.g. the substring \"\\u0123\" will be interpreted as Unicode(0123) -- which may not be what the file creator intended\n",
    "  - these may need to be fixed by loading whole strings and then parsing into a new data frame\n",
    "  \n",
    "Tip: Most issues can be delth with by correctly specifying the parameters of the function you use to load the file. Read the doco before reading the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCfcsBYyPLS7"
   },
   "source": [
    "### Reading Excel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h0CuHGu4PLS8"
   },
   "outputs": [],
   "source": [
    "from pandas import ExcelFile  # Nb. Need to install xlrd from conda (it does not automatically install with pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBSYkArFPLS-",
    "outputId": "23d0ef3d-8b89-4e4a-c962-0a89ba8d52ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species_No</th>\n",
       "      <th>Petal_width</th>\n",
       "      <th>Petal_length</th>\n",
       "      <th>Sepal_width</th>\n",
       "      <th>Sepal_length</th>\n",
       "      <th>Species_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Verginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Species_No  Petal_width  Petal_length  Sepal_width  Sepal_length  \\\n",
       "0             1          0.2           1.4          3.5           5.1   \n",
       "1             1          0.2           1.4          3.0           4.9   \n",
       "2             1          0.2           1.3          3.2           4.7   \n",
       "3             1          0.2           1.5          3.1           4.6   \n",
       "4             1          0.2           1.4          3.6           5.0   \n",
       "5             1          0.4           1.7          3.9           5.4   \n",
       "6             1          0.3           1.4          3.4           4.6   \n",
       "7             1          0.2           1.5          3.4           5.0   \n",
       "8             1          0.2           1.4          2.9           4.4   \n",
       "9             1          0.1           1.5          3.1           4.9   \n",
       "10            1          0.2           1.5          3.7           5.4   \n",
       "11            1          0.2           1.6          3.4           4.8   \n",
       "12            1          0.1           1.4          3.0           4.8   \n",
       "13            1          0.1           1.1          3.0           4.3   \n",
       "14            1          0.2           1.2          4.0           5.8   \n",
       "15            1          0.4           1.5          4.4           5.7   \n",
       "16            1          0.4           1.3          3.9           5.4   \n",
       "17            1          0.3           1.4          3.5           5.1   \n",
       "18            1          0.3           1.7          3.8           5.7   \n",
       "19            1          0.3           1.5          3.8           5.1   \n",
       "20            1          0.2           1.7          3.4           5.4   \n",
       "21            1          0.4           1.5          3.7           5.1   \n",
       "22            1          0.2           1.0          3.6           4.6   \n",
       "23            1          0.5           1.7          3.3           5.1   \n",
       "24            1          0.2           1.9          3.4           4.8   \n",
       "25            1          0.2           1.6          3.0           5.0   \n",
       "26            1          0.4           1.6          3.4           5.0   \n",
       "27            1          0.2           1.5          3.5           5.2   \n",
       "28            1          0.2           1.4          3.4           5.2   \n",
       "29            1          0.2           1.6          3.2           4.7   \n",
       "..          ...          ...           ...          ...           ...   \n",
       "120           3          2.3           5.7          3.2           6.9   \n",
       "121           3          2.0           4.9          2.8           5.6   \n",
       "122           3          2.0           6.7          2.8           7.7   \n",
       "123           3          1.8           4.9          2.7           6.3   \n",
       "124           3          2.1           5.7          3.3           6.7   \n",
       "125           3          1.8           6.0          3.2           7.2   \n",
       "126           3          1.8           4.8          2.8           6.2   \n",
       "127           3          1.8           4.9          3.0           6.1   \n",
       "128           3          2.1           5.6          2.8           6.4   \n",
       "129           3          1.6           5.8          3.0           7.2   \n",
       "130           3          1.9           6.1          2.8           7.4   \n",
       "131           3          2.0           6.4          3.8           7.9   \n",
       "132           3          2.2           5.6          2.8           6.4   \n",
       "133           3          1.5           5.1          2.8           6.3   \n",
       "134           3          1.4           5.6          2.6           6.1   \n",
       "135           3          2.3           6.1          3.0           7.7   \n",
       "136           3          2.4           5.6          3.4           6.3   \n",
       "137           3          1.8           5.5          3.1           6.4   \n",
       "138           3          1.8           4.8          3.0           6.0   \n",
       "139           3          2.1           5.4          3.1           6.9   \n",
       "140           3          2.4           5.6          3.1           6.7   \n",
       "141           3          2.3           5.1          3.1           6.9   \n",
       "142           3          1.9           5.1          2.7           5.8   \n",
       "143           3          2.3           5.9          3.2           6.8   \n",
       "144           3          2.5           5.7          3.3           6.7   \n",
       "145           3          2.3           5.2          3.0           6.7   \n",
       "146           3          1.9           5.0          2.5           6.3   \n",
       "147           3          2.0           5.2          3.0           6.5   \n",
       "148           3          2.3           5.4          3.4           6.2   \n",
       "149           3          1.8           5.1          3.0           5.9   \n",
       "\n",
       "    Species_name  \n",
       "0         Setosa  \n",
       "1         Setosa  \n",
       "2         Setosa  \n",
       "3         Setosa  \n",
       "4         Setosa  \n",
       "5         Setosa  \n",
       "6         Setosa  \n",
       "7         Setosa  \n",
       "8         Setosa  \n",
       "9         Setosa  \n",
       "10        Setosa  \n",
       "11        Setosa  \n",
       "12        Setosa  \n",
       "13        Setosa  \n",
       "14        Setosa  \n",
       "15        Setosa  \n",
       "16        Setosa  \n",
       "17        Setosa  \n",
       "18        Setosa  \n",
       "19        Setosa  \n",
       "20        Setosa  \n",
       "21        Setosa  \n",
       "22        Setosa  \n",
       "23        Setosa  \n",
       "24        Setosa  \n",
       "25        Setosa  \n",
       "26        Setosa  \n",
       "27        Setosa  \n",
       "28        Setosa  \n",
       "29        Setosa  \n",
       "..           ...  \n",
       "120    Verginica  \n",
       "121    Verginica  \n",
       "122    Verginica  \n",
       "123    Verginica  \n",
       "124    Verginica  \n",
       "125    Verginica  \n",
       "126    Verginica  \n",
       "127    Verginica  \n",
       "128    Verginica  \n",
       "129    Verginica  \n",
       "130    Verginica  \n",
       "131    Verginica  \n",
       "132    Verginica  \n",
       "133    Verginica  \n",
       "134    Verginica  \n",
       "135    Verginica  \n",
       "136    Verginica  \n",
       "137    Verginica  \n",
       "138    Verginica  \n",
       "139    Verginica  \n",
       "140    Verginica  \n",
       "141    Verginica  \n",
       "142    Verginica  \n",
       "143    Verginica  \n",
       "144    Verginica  \n",
       "145    Verginica  \n",
       "146    Verginica  \n",
       "147    Verginica  \n",
       "148    Verginica  \n",
       "149    Verginica  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../../../DATA/Iris.xls', sheet_name = 'Data')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnwmdyxbPLTA"
   },
   "source": [
    "So, this file appears to have an embedded table of aggregates on the same sheet as the raw data (a naughty but common practice amongst analysts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpxddhTdPLTB"
   },
   "source": [
    "It is usually better to load data correctly than to meddle with the source file or load it 'warts and all' and then try to parse it in code. The Pandas functions for reading files have parameters that provide the control we need. For ecxample, we could make multiple calls to `read_excel()`, using combinations of the `header`, `usecols`, `skiprows`, `nrows`, and `skipfooter` parameters to load one table at a time from a spreadsheet with multiple tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghX-LShYPLTB"
   },
   "source": [
    "Load the above file without the unwanted columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jKoWOPiJPLTC",
    "outputId": "bb8838de-a85e-47bc-c4cd-0a59c20cc664"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species_No</th>\n",
       "      <th>Petal_width</th>\n",
       "      <th>Petal_length</th>\n",
       "      <th>Sepal_width</th>\n",
       "      <th>Sepal_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Species_No  Petal_width  Petal_length  Sepal_width  Sepal_length\n",
       "0             1          0.2           1.4          3.5           5.1\n",
       "1             1          0.2           1.4          3.0           4.9\n",
       "2             1          0.2           1.3          3.2           4.7\n",
       "3             1          0.2           1.5          3.1           4.6\n",
       "4             1          0.2           1.4          3.6           5.0\n",
       "5             1          0.4           1.7          3.9           5.4\n",
       "6             1          0.3           1.4          3.4           4.6\n",
       "7             1          0.2           1.5          3.4           5.0\n",
       "8             1          0.2           1.4          2.9           4.4\n",
       "9             1          0.1           1.5          3.1           4.9\n",
       "10            1          0.2           1.5          3.7           5.4\n",
       "11            1          0.2           1.6          3.4           4.8\n",
       "12            1          0.1           1.4          3.0           4.8\n",
       "13            1          0.1           1.1          3.0           4.3\n",
       "14            1          0.2           1.2          4.0           5.8\n",
       "15            1          0.4           1.5          4.4           5.7\n",
       "16            1          0.4           1.3          3.9           5.4\n",
       "17            1          0.3           1.4          3.5           5.1\n",
       "18            1          0.3           1.7          3.8           5.7\n",
       "19            1          0.3           1.5          3.8           5.1\n",
       "20            1          0.2           1.7          3.4           5.4\n",
       "21            1          0.4           1.5          3.7           5.1\n",
       "22            1          0.2           1.0          3.6           4.6\n",
       "23            1          0.5           1.7          3.3           5.1\n",
       "24            1          0.2           1.9          3.4           4.8\n",
       "25            1          0.2           1.6          3.0           5.0\n",
       "26            1          0.4           1.6          3.4           5.0\n",
       "27            1          0.2           1.5          3.5           5.2\n",
       "28            1          0.2           1.4          3.4           5.2\n",
       "29            1          0.2           1.6          3.2           4.7\n",
       "..          ...          ...           ...          ...           ...\n",
       "120           3          2.3           5.7          3.2           6.9\n",
       "121           3          2.0           4.9          2.8           5.6\n",
       "122           3          2.0           6.7          2.8           7.7\n",
       "123           3          1.8           4.9          2.7           6.3\n",
       "124           3          2.1           5.7          3.3           6.7\n",
       "125           3          1.8           6.0          3.2           7.2\n",
       "126           3          1.8           4.8          2.8           6.2\n",
       "127           3          1.8           4.9          3.0           6.1\n",
       "128           3          2.1           5.6          2.8           6.4\n",
       "129           3          1.6           5.8          3.0           7.2\n",
       "130           3          1.9           6.1          2.8           7.4\n",
       "131           3          2.0           6.4          3.8           7.9\n",
       "132           3          2.2           5.6          2.8           6.4\n",
       "133           3          1.5           5.1          2.8           6.3\n",
       "134           3          1.4           5.6          2.6           6.1\n",
       "135           3          2.3           6.1          3.0           7.7\n",
       "136           3          2.4           5.6          3.4           6.3\n",
       "137           3          1.8           5.5          3.1           6.4\n",
       "138           3          1.8           4.8          3.0           6.0\n",
       "139           3          2.1           5.4          3.1           6.9\n",
       "140           3          2.4           5.6          3.1           6.7\n",
       "141           3          2.3           5.1          3.1           6.9\n",
       "142           3          1.9           5.1          2.7           5.8\n",
       "143           3          2.3           5.9          3.2           6.8\n",
       "144           3          2.5           5.7          3.3           6.7\n",
       "145           3          2.3           5.2          3.0           6.7\n",
       "146           3          1.9           5.0          2.5           6.3\n",
       "147           3          2.0           5.2          3.0           6.5\n",
       "148           3          2.3           5.4          3.4           6.2\n",
       "149           3          1.8           5.1          3.0           5.9\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "df = pd.read_excel('../../../DATA/Iris.xls', sheet_name = 'Data', header = 0, usecols = [0, 1, 2, 3, 4])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9XLZahIPLTF"
   },
   "source": [
    "### Importing Data Directly from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLAV3sPSPLTF"
   },
   "source": [
    "We usually want to store a local copy of a data file that we download from the Web, but when data retention is not a priority it is convenient to download the data directly into our running Python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gnyWmX1PLTG"
   },
   "source": [
    "#### Importing Text Files from the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vp43zyPpPLTG"
   },
   "source": [
    "The web is the 'wild west' of data formats. However, we can usually expect good behaviour from files that are automatically generated by a service, such as the earthquake report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EU45gBN0PLTG",
    "outputId": "97a1d60d-c625-4388-bacc-e12287afb1d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>magType</th>\n",
       "      <th>nst</th>\n",
       "      <th>gap</th>\n",
       "      <th>dmin</th>\n",
       "      <th>rms</th>\n",
       "      <th>...</th>\n",
       "      <th>updated</th>\n",
       "      <th>place</th>\n",
       "      <th>type</th>\n",
       "      <th>horizontalError</th>\n",
       "      <th>depthError</th>\n",
       "      <th>magError</th>\n",
       "      <th>magNst</th>\n",
       "      <th>status</th>\n",
       "      <th>locationSource</th>\n",
       "      <th>magSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-29T20:45:26.309Z</td>\n",
       "      <td>17.008900</td>\n",
       "      <td>-66.475600</td>\n",
       "      <td>10</td>\n",
       "      <td>2.80</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>0.981000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-03-29T20:58:21.040Z</td>\n",
       "      <td>106km S of Santa Isabel, Puerto Rico</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.076</td>\n",
       "      <td>23</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-29T20:34:36.927Z</td>\n",
       "      <td>35.096333</td>\n",
       "      <td>-95.274689</td>\n",
       "      <td>5</td>\n",
       "      <td>2.64</td>\n",
       "      <td>ml</td>\n",
       "      <td>28.0</td>\n",
       "      <td>204.205658</td>\n",
       "      <td>0.191161</td>\n",
       "      <td>0.616913</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-03-29T20:38:15.180Z</td>\n",
       "      <td>9km ESE of Quinton, Oklahoma</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>4.065633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>automatic</td>\n",
       "      <td>ok</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-29T20:26:00.328Z</td>\n",
       "      <td>13.628600</td>\n",
       "      <td>-91.370100</td>\n",
       "      <td>10</td>\n",
       "      <td>4.60</td>\n",
       "      <td>mb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-03-29T20:59:14.995Z</td>\n",
       "      <td>61km SW of La Gomera, Guatemala</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.051</td>\n",
       "      <td>113</td>\n",
       "      <td>reviewed</td>\n",
       "      <td>us</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time   latitude  longitude  depth   mag magType   nst  \\\n",
       "0  2020-03-29T20:45:26.309Z  17.008900 -66.475600     10  2.80      ml   NaN   \n",
       "1  2020-03-29T20:34:36.927Z  35.096333 -95.274689      5  2.64      ml  28.0   \n",
       "2  2020-03-29T20:26:00.328Z  13.628600 -91.370100     10  4.60      mb   NaN   \n",
       "\n",
       "          gap      dmin       rms  ...                   updated  \\\n",
       "0  326.000000  0.981000  0.820000  ...  2020-03-29T20:58:21.040Z   \n",
       "1  204.205658  0.191161  0.616913  ...  2020-03-29T20:38:15.180Z   \n",
       "2  196.000000  0.944000  1.160000  ...  2020-03-29T20:59:14.995Z   \n",
       "\n",
       "                                  place        type horizontalError  \\\n",
       "0  106km S of Santa Isabel, Puerto Rico  earthquake        8.200000   \n",
       "1          9km ESE of Quinton, Oklahoma  earthquake        4.065633   \n",
       "2       61km SW of La Gomera, Guatemala  earthquake        7.600000   \n",
       "\n",
       "  depthError  magError  magNst     status  locationSource magSource  \n",
       "0        2.0     0.076      23   reviewed              us        us  \n",
       "1        NaN       NaN      22  automatic              ok        ok  \n",
       "2        2.0     0.051     113   reviewed              us        us  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_hour.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLZSU6EsPLTJ"
   },
   "source": [
    "#### Importing HTML Files from the Web\n",
    "\n",
    "Working with unstructured HTML files relies heavily on library functions. This one, however, is well-structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Swc6O7IiPLTK",
    "outputId": "4e7844d2-464e-42ec-a167-cc0e61a4b6ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                             Bank Name                City  \\\n",
       " 0                                   Ericson State Bank             Ericson   \n",
       " 1                     City National Bank of New Jersey              Newark   \n",
       " 2                                        Resolute Bank              Maumee   \n",
       " 3                                Louisa Community Bank              Louisa   \n",
       " 4                                 The Enloe State Bank              Cooper   \n",
       " 5                  Washington Federal Bank for Savings             Chicago   \n",
       " 6      The Farmers and Merchants State Bank of Argonia             Argonia   \n",
       " 7                                  Fayette County Bank          Saint Elmo   \n",
       " 8    Guaranty Bank, (d/b/a BestBank in Georgia & Mi...           Milwaukee   \n",
       " 9                                       First NBC Bank         New Orleans   \n",
       " 10                                       Proficio Bank  Cottonwood Heights   \n",
       " 11                       Seaway Bank and Trust Company             Chicago   \n",
       " 12                              Harvest Community Bank          Pennsville   \n",
       " 13                                         Allied Bank            Mulberry   \n",
       " 14                        The Woodbury Banking Company            Woodbury   \n",
       " 15                              First CornerStone Bank     King of Prussia   \n",
       " 16                                  Trust Company Bank             Memphis   \n",
       " 17                          North Milwaukee State Bank           Milwaukee   \n",
       " 18                              Hometown National Bank            Longview   \n",
       " 19                                 The Bank of Georgia      Peachtree City   \n",
       " 20                                        Premier Bank              Denver   \n",
       " 21                                      Edgebrook Bank             Chicago   \n",
       " 22                              Doral Bank  En Español            San Juan   \n",
       " 23                   Capitol City Bank & Trust Company             Atlanta   \n",
       " 24                             Highland Community Bank             Chicago   \n",
       " 25                    First National Bank of Crestview           Crestview   \n",
       " 26                                  Northern Star Bank             Mankato   \n",
       " 27              Frontier Bank, FSB D/B/A El Paseo Bank         Palm Desert   \n",
       " 28               The National Republic Bank of Chicago             Chicago   \n",
       " 29                                      NBRS Financial          Rising Sun   \n",
       " ..                                                 ...                 ...   \n",
       " 530                                  ANB Financial, NA         Bentonville   \n",
       " 531                                          Hume Bank                Hume   \n",
       " 532                             Douglass National Bank         Kansas City   \n",
       " 533                                  Miami Valley Bank            Lakeview   \n",
       " 534                                            NetBank          Alpharetta   \n",
       " 535                          Metropolitan Savings Bank          Pittsburgh   \n",
       " 536                                    Bank of Ephraim             Ephraim   \n",
       " 537                                      Reliance Bank        White Plains   \n",
       " 538              Guaranty National Bank of Tallahassee         Tallahassee   \n",
       " 539                                Dollar Savings Bank              Newark   \n",
       " 540                               Pulaski Savings Bank        Philadelphia   \n",
       " 541              First National Bank of Blanchardville      Blanchardville   \n",
       " 542                              Southern Pacific Bank            Torrance   \n",
       " 543                        Farmers Bank of Cheneyville         Cheneyville   \n",
       " 544                                      Bank of Alamo               Alamo   \n",
       " 545             AmTrade International Bank  En Español             Atlanta   \n",
       " 546                     Universal Federal Savings Bank             Chicago   \n",
       " 547                       Connecticut Bank of Commerce            Stamford   \n",
       " 548                                   New Century Bank     Shelby Township   \n",
       " 549                              Net 1st National Bank          Boca Raton   \n",
       " 550                                       NextBank, NA             Phoenix   \n",
       " 551                           Oakwood Deposit Bank Co.             Oakwood   \n",
       " 552                              Bank of Sierra Blanca       Sierra Blanca   \n",
       " 553                      Hamilton Bank, NA  En Español               Miami   \n",
       " 554                             Sinclair National Bank            Gravette   \n",
       " 555                                 Superior Bank, FSB            Hinsdale   \n",
       " 556                                Malta National Bank               Malta   \n",
       " 557                    First Alliance Bank & Trust Co.          Manchester   \n",
       " 558                  National State Bank of Metropolis          Metropolis   \n",
       " 559                                   Bank of Honolulu            Honolulu   \n",
       " \n",
       "      ST   CERT                Acquiring Institution        Closing Date  \n",
       " 0    NE  18265           Farmers and Merchants Bank   February 14, 2020  \n",
       " 1    NJ  21111                      Industrial Bank    November 1, 2019  \n",
       " 2    OH  58317                   Buckeye State Bank    October 25, 2019  \n",
       " 3    KY  58112    Kentucky Farmers Bank Corporation    October 25, 2019  \n",
       " 4    TX  10716                   Legend Bank, N. A.        May 31, 2019  \n",
       " 5    IL  30570                   Royal Savings Bank   December 15, 2017  \n",
       " 6    KS  17719                          Conway Bank    October 13, 2017  \n",
       " 7    IL   1802            United Fidelity Bank, fsb        May 26, 2017  \n",
       " 8    WI  30003  First-Citizens Bank & Trust Company         May 5, 2017  \n",
       " 9    LA  58302                         Whitney Bank      April 28, 2017  \n",
       " 10   UT  35495                    Cache Valley Bank       March 3, 2017  \n",
       " 11   IL  19328                  State Bank of Texas    January 27, 2017  \n",
       " 12   NJ  34951  First-Citizens Bank & Trust Company    January 13, 2017  \n",
       " 13   AR     91                         Today's Bank  September 23, 2016  \n",
       " 14   GA  11297                          United Bank     August 19, 2016  \n",
       " 15   PA  35312  First-Citizens Bank & Trust Company         May 6, 2016  \n",
       " 16   TN   9956           The Bank of Fayette County      April 29, 2016  \n",
       " 17   WI  20364  First-Citizens Bank & Trust Company      March 11, 2016  \n",
       " 18   WA  35156                       Twin City Bank     October 2, 2015  \n",
       " 19   GA  35259                        Fidelity Bank     October 2, 2015  \n",
       " 20   CO  34112            United Fidelity Bank, fsb       July 10, 2015  \n",
       " 21   IL  57772             Republic Bank of Chicago         May 8, 2015  \n",
       " 22   PR  32102         Banco Popular de Puerto Rico   February 27, 2015  \n",
       " 23   GA  33938  First-Citizens Bank & Trust Company   February 13, 2015  \n",
       " 24   IL  20290            United Fidelity Bank, fsb    January 23, 2015  \n",
       " 25   FL  17557                       First NBC Bank    January 16, 2015  \n",
       " 26   MN  34983                            BankVista   December 19, 2014  \n",
       " 27   CA  34738    Bank of Southern California, N.A.    November 7, 2014  \n",
       " 28   IL    916                  State Bank of Texas    October 24, 2014  \n",
       " 29   MD   4862                          Howard Bank    October 17, 2014  \n",
       " ..   ..    ...                                  ...                 ...  \n",
       " 530  AR  33901       Pulaski Bank and Trust Company         May 9, 2008  \n",
       " 531  MO   1971                        Security Bank       March 7, 2008  \n",
       " 532  MO  24660       Liberty Bank and Trust Company    January 25, 2008  \n",
       " 533  OH  16848         The Citizens Banking Company     October 4, 2007  \n",
       " 534  GA  32575                           ING DIRECT  September 28, 2007  \n",
       " 535  PA  35353  Allegheny Valley Bank of Pittsburgh    February 2, 2007  \n",
       " 536  UT   1249                        Far West Bank       June 25, 2004  \n",
       " 537  NY  26778                     Union State Bank      March 19, 2004  \n",
       " 538  FL  26838              Hancock Bank of Florida      March 12, 2004  \n",
       " 539  NJ  31330                          No Acquirer   February 14, 2004  \n",
       " 540  PA  27203                       Earthstar Bank   November 14, 2003  \n",
       " 541  WI  11639                        The Park Bank         May 9, 2003  \n",
       " 542  CA  27094                            Beal Bank    February 7, 2003  \n",
       " 543  LA  16445            Sabine State Bank & Trust   December 17, 2002  \n",
       " 544  TN   9961                          No Acquirer    November 8, 2002  \n",
       " 545  GA  33784                          No Acquirer  September 30, 2002  \n",
       " 546  IL  29355               Chicago Community Bank       June 27, 2002  \n",
       " 547  CT  19183                   Hudson United Bank       June 26, 2002  \n",
       " 548  MI  34979                          No Acquirer      March 28, 2002  \n",
       " 549  FL  26652                       Bank Leumi USA       March 1, 2002  \n",
       " 550  AZ  22314                          No Acquirer    February 7, 2002  \n",
       " 551  OH   8966       The State Bank & Trust Company    February 1, 2002  \n",
       " 552  TX  22002     The Security State Bank of Pecos    January 18, 2002  \n",
       " 553  FL  24382     Israel Discount Bank of New York    January 11, 2002  \n",
       " 554  AR  34248                   Delta Trust & Bank   September 7, 2001  \n",
       " 555  IL  32646                Superior Federal, FSB       July 27, 2001  \n",
       " 556  OH   6629                    North Valley Bank         May 3, 2001  \n",
       " 557  NH  34264  Southern New Hampshire Bank & Trust    February 2, 2001  \n",
       " 558  IL   3815              Banterra Bank of Marion   December 14, 2000  \n",
       " 559  HI  21029                   Bank of the Orient    October 13, 2000  \n",
       " \n",
       " [560 rows x 6 columns]]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/'\n",
    "df = pd.read_html(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5TUaZngWumk",
    "outputId": "e23c54f5-fa77-4b75-fcbb-63ba61aa15a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bank Name</th>\n",
       "      <th>City</th>\n",
       "      <th>ST</th>\n",
       "      <th>CERT</th>\n",
       "      <th>Acquiring Institution</th>\n",
       "      <th>Closing Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ericson State Bank</td>\n",
       "      <td>Ericson</td>\n",
       "      <td>NE</td>\n",
       "      <td>18265</td>\n",
       "      <td>Farmers and Merchants Bank</td>\n",
       "      <td>February 14, 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City National Bank of New Jersey</td>\n",
       "      <td>Newark</td>\n",
       "      <td>NJ</td>\n",
       "      <td>21111</td>\n",
       "      <td>Industrial Bank</td>\n",
       "      <td>November 1, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resolute Bank</td>\n",
       "      <td>Maumee</td>\n",
       "      <td>OH</td>\n",
       "      <td>58317</td>\n",
       "      <td>Buckeye State Bank</td>\n",
       "      <td>October 25, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Louisa Community Bank</td>\n",
       "      <td>Louisa</td>\n",
       "      <td>KY</td>\n",
       "      <td>58112</td>\n",
       "      <td>Kentucky Farmers Bank Corporation</td>\n",
       "      <td>October 25, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Enloe State Bank</td>\n",
       "      <td>Cooper</td>\n",
       "      <td>TX</td>\n",
       "      <td>10716</td>\n",
       "      <td>Legend Bank, N. A.</td>\n",
       "      <td>May 31, 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Washington Federal Bank for Savings</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>30570</td>\n",
       "      <td>Royal Savings Bank</td>\n",
       "      <td>December 15, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Farmers and Merchants State Bank of Argonia</td>\n",
       "      <td>Argonia</td>\n",
       "      <td>KS</td>\n",
       "      <td>17719</td>\n",
       "      <td>Conway Bank</td>\n",
       "      <td>October 13, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fayette County Bank</td>\n",
       "      <td>Saint Elmo</td>\n",
       "      <td>IL</td>\n",
       "      <td>1802</td>\n",
       "      <td>United Fidelity Bank, fsb</td>\n",
       "      <td>May 26, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Guaranty Bank, (d/b/a BestBank in Georgia &amp; Mi...</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>WI</td>\n",
       "      <td>30003</td>\n",
       "      <td>First-Citizens Bank &amp; Trust Company</td>\n",
       "      <td>May 5, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>First NBC Bank</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>LA</td>\n",
       "      <td>58302</td>\n",
       "      <td>Whitney Bank</td>\n",
       "      <td>April 28, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Proficio Bank</td>\n",
       "      <td>Cottonwood Heights</td>\n",
       "      <td>UT</td>\n",
       "      <td>35495</td>\n",
       "      <td>Cache Valley Bank</td>\n",
       "      <td>March 3, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Seaway Bank and Trust Company</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>19328</td>\n",
       "      <td>State Bank of Texas</td>\n",
       "      <td>January 27, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Harvest Community Bank</td>\n",
       "      <td>Pennsville</td>\n",
       "      <td>NJ</td>\n",
       "      <td>34951</td>\n",
       "      <td>First-Citizens Bank &amp; Trust Company</td>\n",
       "      <td>January 13, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Allied Bank</td>\n",
       "      <td>Mulberry</td>\n",
       "      <td>AR</td>\n",
       "      <td>91</td>\n",
       "      <td>Today's Bank</td>\n",
       "      <td>September 23, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Woodbury Banking Company</td>\n",
       "      <td>Woodbury</td>\n",
       "      <td>GA</td>\n",
       "      <td>11297</td>\n",
       "      <td>United Bank</td>\n",
       "      <td>August 19, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>First CornerStone Bank</td>\n",
       "      <td>King of Prussia</td>\n",
       "      <td>PA</td>\n",
       "      <td>35312</td>\n",
       "      <td>First-Citizens Bank &amp; Trust Company</td>\n",
       "      <td>May 6, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Trust Company Bank</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>TN</td>\n",
       "      <td>9956</td>\n",
       "      <td>The Bank of Fayette County</td>\n",
       "      <td>April 29, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>North Milwaukee State Bank</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>WI</td>\n",
       "      <td>20364</td>\n",
       "      <td>First-Citizens Bank &amp; Trust Company</td>\n",
       "      <td>March 11, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Hometown National Bank</td>\n",
       "      <td>Longview</td>\n",
       "      <td>WA</td>\n",
       "      <td>35156</td>\n",
       "      <td>Twin City Bank</td>\n",
       "      <td>October 2, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The Bank of Georgia</td>\n",
       "      <td>Peachtree City</td>\n",
       "      <td>GA</td>\n",
       "      <td>35259</td>\n",
       "      <td>Fidelity Bank</td>\n",
       "      <td>October 2, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Premier Bank</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "      <td>34112</td>\n",
       "      <td>United Fidelity Bank, fsb</td>\n",
       "      <td>July 10, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Edgebrook Bank</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>57772</td>\n",
       "      <td>Republic Bank of Chicago</td>\n",
       "      <td>May 8, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Doral Bank  En Español</td>\n",
       "      <td>San Juan</td>\n",
       "      <td>PR</td>\n",
       "      <td>32102</td>\n",
       "      <td>Banco Popular de Puerto Rico</td>\n",
       "      <td>February 27, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Capitol City Bank &amp; Trust Company</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>33938</td>\n",
       "      <td>First-Citizens Bank &amp; Trust Company</td>\n",
       "      <td>February 13, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Highland Community Bank</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>20290</td>\n",
       "      <td>United Fidelity Bank, fsb</td>\n",
       "      <td>January 23, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>First National Bank of Crestview</td>\n",
       "      <td>Crestview</td>\n",
       "      <td>FL</td>\n",
       "      <td>17557</td>\n",
       "      <td>First NBC Bank</td>\n",
       "      <td>January 16, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Northern Star Bank</td>\n",
       "      <td>Mankato</td>\n",
       "      <td>MN</td>\n",
       "      <td>34983</td>\n",
       "      <td>BankVista</td>\n",
       "      <td>December 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Frontier Bank, FSB D/B/A El Paseo Bank</td>\n",
       "      <td>Palm Desert</td>\n",
       "      <td>CA</td>\n",
       "      <td>34738</td>\n",
       "      <td>Bank of Southern California, N.A.</td>\n",
       "      <td>November 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>The National Republic Bank of Chicago</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>916</td>\n",
       "      <td>State Bank of Texas</td>\n",
       "      <td>October 24, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NBRS Financial</td>\n",
       "      <td>Rising Sun</td>\n",
       "      <td>MD</td>\n",
       "      <td>4862</td>\n",
       "      <td>Howard Bank</td>\n",
       "      <td>October 17, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>ANB Financial, NA</td>\n",
       "      <td>Bentonville</td>\n",
       "      <td>AR</td>\n",
       "      <td>33901</td>\n",
       "      <td>Pulaski Bank and Trust Company</td>\n",
       "      <td>May 9, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>Hume Bank</td>\n",
       "      <td>Hume</td>\n",
       "      <td>MO</td>\n",
       "      <td>1971</td>\n",
       "      <td>Security Bank</td>\n",
       "      <td>March 7, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>Douglass National Bank</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>MO</td>\n",
       "      <td>24660</td>\n",
       "      <td>Liberty Bank and Trust Company</td>\n",
       "      <td>January 25, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>Miami Valley Bank</td>\n",
       "      <td>Lakeview</td>\n",
       "      <td>OH</td>\n",
       "      <td>16848</td>\n",
       "      <td>The Citizens Banking Company</td>\n",
       "      <td>October 4, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>NetBank</td>\n",
       "      <td>Alpharetta</td>\n",
       "      <td>GA</td>\n",
       "      <td>32575</td>\n",
       "      <td>ING DIRECT</td>\n",
       "      <td>September 28, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>Metropolitan Savings Bank</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>35353</td>\n",
       "      <td>Allegheny Valley Bank of Pittsburgh</td>\n",
       "      <td>February 2, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>Bank of Ephraim</td>\n",
       "      <td>Ephraim</td>\n",
       "      <td>UT</td>\n",
       "      <td>1249</td>\n",
       "      <td>Far West Bank</td>\n",
       "      <td>June 25, 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>Reliance Bank</td>\n",
       "      <td>White Plains</td>\n",
       "      <td>NY</td>\n",
       "      <td>26778</td>\n",
       "      <td>Union State Bank</td>\n",
       "      <td>March 19, 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>Guaranty National Bank of Tallahassee</td>\n",
       "      <td>Tallahassee</td>\n",
       "      <td>FL</td>\n",
       "      <td>26838</td>\n",
       "      <td>Hancock Bank of Florida</td>\n",
       "      <td>March 12, 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>Dollar Savings Bank</td>\n",
       "      <td>Newark</td>\n",
       "      <td>NJ</td>\n",
       "      <td>31330</td>\n",
       "      <td>No Acquirer</td>\n",
       "      <td>February 14, 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>Pulaski Savings Bank</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>27203</td>\n",
       "      <td>Earthstar Bank</td>\n",
       "      <td>November 14, 2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>First National Bank of Blanchardville</td>\n",
       "      <td>Blanchardville</td>\n",
       "      <td>WI</td>\n",
       "      <td>11639</td>\n",
       "      <td>The Park Bank</td>\n",
       "      <td>May 9, 2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>Southern Pacific Bank</td>\n",
       "      <td>Torrance</td>\n",
       "      <td>CA</td>\n",
       "      <td>27094</td>\n",
       "      <td>Beal Bank</td>\n",
       "      <td>February 7, 2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>Farmers Bank of Cheneyville</td>\n",
       "      <td>Cheneyville</td>\n",
       "      <td>LA</td>\n",
       "      <td>16445</td>\n",
       "      <td>Sabine State Bank &amp; Trust</td>\n",
       "      <td>December 17, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>Bank of Alamo</td>\n",
       "      <td>Alamo</td>\n",
       "      <td>TN</td>\n",
       "      <td>9961</td>\n",
       "      <td>No Acquirer</td>\n",
       "      <td>November 8, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>AmTrade International Bank  En Español</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "      <td>33784</td>\n",
       "      <td>No Acquirer</td>\n",
       "      <td>September 30, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>Universal Federal Savings Bank</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>29355</td>\n",
       "      <td>Chicago Community Bank</td>\n",
       "      <td>June 27, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>Connecticut Bank of Commerce</td>\n",
       "      <td>Stamford</td>\n",
       "      <td>CT</td>\n",
       "      <td>19183</td>\n",
       "      <td>Hudson United Bank</td>\n",
       "      <td>June 26, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>New Century Bank</td>\n",
       "      <td>Shelby Township</td>\n",
       "      <td>MI</td>\n",
       "      <td>34979</td>\n",
       "      <td>No Acquirer</td>\n",
       "      <td>March 28, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Net 1st National Bank</td>\n",
       "      <td>Boca Raton</td>\n",
       "      <td>FL</td>\n",
       "      <td>26652</td>\n",
       "      <td>Bank Leumi USA</td>\n",
       "      <td>March 1, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>NextBank, NA</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>AZ</td>\n",
       "      <td>22314</td>\n",
       "      <td>No Acquirer</td>\n",
       "      <td>February 7, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>Oakwood Deposit Bank Co.</td>\n",
       "      <td>Oakwood</td>\n",
       "      <td>OH</td>\n",
       "      <td>8966</td>\n",
       "      <td>The State Bank &amp; Trust Company</td>\n",
       "      <td>February 1, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>Bank of Sierra Blanca</td>\n",
       "      <td>Sierra Blanca</td>\n",
       "      <td>TX</td>\n",
       "      <td>22002</td>\n",
       "      <td>The Security State Bank of Pecos</td>\n",
       "      <td>January 18, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>Hamilton Bank, NA  En Español</td>\n",
       "      <td>Miami</td>\n",
       "      <td>FL</td>\n",
       "      <td>24382</td>\n",
       "      <td>Israel Discount Bank of New York</td>\n",
       "      <td>January 11, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>Sinclair National Bank</td>\n",
       "      <td>Gravette</td>\n",
       "      <td>AR</td>\n",
       "      <td>34248</td>\n",
       "      <td>Delta Trust &amp; Bank</td>\n",
       "      <td>September 7, 2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>Superior Bank, FSB</td>\n",
       "      <td>Hinsdale</td>\n",
       "      <td>IL</td>\n",
       "      <td>32646</td>\n",
       "      <td>Superior Federal, FSB</td>\n",
       "      <td>July 27, 2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>Malta National Bank</td>\n",
       "      <td>Malta</td>\n",
       "      <td>OH</td>\n",
       "      <td>6629</td>\n",
       "      <td>North Valley Bank</td>\n",
       "      <td>May 3, 2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>First Alliance Bank &amp; Trust Co.</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>NH</td>\n",
       "      <td>34264</td>\n",
       "      <td>Southern New Hampshire Bank &amp; Trust</td>\n",
       "      <td>February 2, 2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>National State Bank of Metropolis</td>\n",
       "      <td>Metropolis</td>\n",
       "      <td>IL</td>\n",
       "      <td>3815</td>\n",
       "      <td>Banterra Bank of Marion</td>\n",
       "      <td>December 14, 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>Bank of Honolulu</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>HI</td>\n",
       "      <td>21029</td>\n",
       "      <td>Bank of the Orient</td>\n",
       "      <td>October 13, 2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Bank Name                City  \\\n",
       "0                                   Ericson State Bank             Ericson   \n",
       "1                     City National Bank of New Jersey              Newark   \n",
       "2                                        Resolute Bank              Maumee   \n",
       "3                                Louisa Community Bank              Louisa   \n",
       "4                                 The Enloe State Bank              Cooper   \n",
       "5                  Washington Federal Bank for Savings             Chicago   \n",
       "6      The Farmers and Merchants State Bank of Argonia             Argonia   \n",
       "7                                  Fayette County Bank          Saint Elmo   \n",
       "8    Guaranty Bank, (d/b/a BestBank in Georgia & Mi...           Milwaukee   \n",
       "9                                       First NBC Bank         New Orleans   \n",
       "10                                       Proficio Bank  Cottonwood Heights   \n",
       "11                       Seaway Bank and Trust Company             Chicago   \n",
       "12                              Harvest Community Bank          Pennsville   \n",
       "13                                         Allied Bank            Mulberry   \n",
       "14                        The Woodbury Banking Company            Woodbury   \n",
       "15                              First CornerStone Bank     King of Prussia   \n",
       "16                                  Trust Company Bank             Memphis   \n",
       "17                          North Milwaukee State Bank           Milwaukee   \n",
       "18                              Hometown National Bank            Longview   \n",
       "19                                 The Bank of Georgia      Peachtree City   \n",
       "20                                        Premier Bank              Denver   \n",
       "21                                      Edgebrook Bank             Chicago   \n",
       "22                              Doral Bank  En Español            San Juan   \n",
       "23                   Capitol City Bank & Trust Company             Atlanta   \n",
       "24                             Highland Community Bank             Chicago   \n",
       "25                    First National Bank of Crestview           Crestview   \n",
       "26                                  Northern Star Bank             Mankato   \n",
       "27              Frontier Bank, FSB D/B/A El Paseo Bank         Palm Desert   \n",
       "28               The National Republic Bank of Chicago             Chicago   \n",
       "29                                      NBRS Financial          Rising Sun   \n",
       "..                                                 ...                 ...   \n",
       "530                                  ANB Financial, NA         Bentonville   \n",
       "531                                          Hume Bank                Hume   \n",
       "532                             Douglass National Bank         Kansas City   \n",
       "533                                  Miami Valley Bank            Lakeview   \n",
       "534                                            NetBank          Alpharetta   \n",
       "535                          Metropolitan Savings Bank          Pittsburgh   \n",
       "536                                    Bank of Ephraim             Ephraim   \n",
       "537                                      Reliance Bank        White Plains   \n",
       "538              Guaranty National Bank of Tallahassee         Tallahassee   \n",
       "539                                Dollar Savings Bank              Newark   \n",
       "540                               Pulaski Savings Bank        Philadelphia   \n",
       "541              First National Bank of Blanchardville      Blanchardville   \n",
       "542                              Southern Pacific Bank            Torrance   \n",
       "543                        Farmers Bank of Cheneyville         Cheneyville   \n",
       "544                                      Bank of Alamo               Alamo   \n",
       "545             AmTrade International Bank  En Español             Atlanta   \n",
       "546                     Universal Federal Savings Bank             Chicago   \n",
       "547                       Connecticut Bank of Commerce            Stamford   \n",
       "548                                   New Century Bank     Shelby Township   \n",
       "549                              Net 1st National Bank          Boca Raton   \n",
       "550                                       NextBank, NA             Phoenix   \n",
       "551                           Oakwood Deposit Bank Co.             Oakwood   \n",
       "552                              Bank of Sierra Blanca       Sierra Blanca   \n",
       "553                      Hamilton Bank, NA  En Español               Miami   \n",
       "554                             Sinclair National Bank            Gravette   \n",
       "555                                 Superior Bank, FSB            Hinsdale   \n",
       "556                                Malta National Bank               Malta   \n",
       "557                    First Alliance Bank & Trust Co.          Manchester   \n",
       "558                  National State Bank of Metropolis          Metropolis   \n",
       "559                                   Bank of Honolulu            Honolulu   \n",
       "\n",
       "     ST   CERT                Acquiring Institution        Closing Date  \n",
       "0    NE  18265           Farmers and Merchants Bank   February 14, 2020  \n",
       "1    NJ  21111                      Industrial Bank    November 1, 2019  \n",
       "2    OH  58317                   Buckeye State Bank    October 25, 2019  \n",
       "3    KY  58112    Kentucky Farmers Bank Corporation    October 25, 2019  \n",
       "4    TX  10716                   Legend Bank, N. A.        May 31, 2019  \n",
       "5    IL  30570                   Royal Savings Bank   December 15, 2017  \n",
       "6    KS  17719                          Conway Bank    October 13, 2017  \n",
       "7    IL   1802            United Fidelity Bank, fsb        May 26, 2017  \n",
       "8    WI  30003  First-Citizens Bank & Trust Company         May 5, 2017  \n",
       "9    LA  58302                         Whitney Bank      April 28, 2017  \n",
       "10   UT  35495                    Cache Valley Bank       March 3, 2017  \n",
       "11   IL  19328                  State Bank of Texas    January 27, 2017  \n",
       "12   NJ  34951  First-Citizens Bank & Trust Company    January 13, 2017  \n",
       "13   AR     91                         Today's Bank  September 23, 2016  \n",
       "14   GA  11297                          United Bank     August 19, 2016  \n",
       "15   PA  35312  First-Citizens Bank & Trust Company         May 6, 2016  \n",
       "16   TN   9956           The Bank of Fayette County      April 29, 2016  \n",
       "17   WI  20364  First-Citizens Bank & Trust Company      March 11, 2016  \n",
       "18   WA  35156                       Twin City Bank     October 2, 2015  \n",
       "19   GA  35259                        Fidelity Bank     October 2, 2015  \n",
       "20   CO  34112            United Fidelity Bank, fsb       July 10, 2015  \n",
       "21   IL  57772             Republic Bank of Chicago         May 8, 2015  \n",
       "22   PR  32102         Banco Popular de Puerto Rico   February 27, 2015  \n",
       "23   GA  33938  First-Citizens Bank & Trust Company   February 13, 2015  \n",
       "24   IL  20290            United Fidelity Bank, fsb    January 23, 2015  \n",
       "25   FL  17557                       First NBC Bank    January 16, 2015  \n",
       "26   MN  34983                            BankVista   December 19, 2014  \n",
       "27   CA  34738    Bank of Southern California, N.A.    November 7, 2014  \n",
       "28   IL    916                  State Bank of Texas    October 24, 2014  \n",
       "29   MD   4862                          Howard Bank    October 17, 2014  \n",
       "..   ..    ...                                  ...                 ...  \n",
       "530  AR  33901       Pulaski Bank and Trust Company         May 9, 2008  \n",
       "531  MO   1971                        Security Bank       March 7, 2008  \n",
       "532  MO  24660       Liberty Bank and Trust Company    January 25, 2008  \n",
       "533  OH  16848         The Citizens Banking Company     October 4, 2007  \n",
       "534  GA  32575                           ING DIRECT  September 28, 2007  \n",
       "535  PA  35353  Allegheny Valley Bank of Pittsburgh    February 2, 2007  \n",
       "536  UT   1249                        Far West Bank       June 25, 2004  \n",
       "537  NY  26778                     Union State Bank      March 19, 2004  \n",
       "538  FL  26838              Hancock Bank of Florida      March 12, 2004  \n",
       "539  NJ  31330                          No Acquirer   February 14, 2004  \n",
       "540  PA  27203                       Earthstar Bank   November 14, 2003  \n",
       "541  WI  11639                        The Park Bank         May 9, 2003  \n",
       "542  CA  27094                            Beal Bank    February 7, 2003  \n",
       "543  LA  16445            Sabine State Bank & Trust   December 17, 2002  \n",
       "544  TN   9961                          No Acquirer    November 8, 2002  \n",
       "545  GA  33784                          No Acquirer  September 30, 2002  \n",
       "546  IL  29355               Chicago Community Bank       June 27, 2002  \n",
       "547  CT  19183                   Hudson United Bank       June 26, 2002  \n",
       "548  MI  34979                          No Acquirer      March 28, 2002  \n",
       "549  FL  26652                       Bank Leumi USA       March 1, 2002  \n",
       "550  AZ  22314                          No Acquirer    February 7, 2002  \n",
       "551  OH   8966       The State Bank & Trust Company    February 1, 2002  \n",
       "552  TX  22002     The Security State Bank of Pecos    January 18, 2002  \n",
       "553  FL  24382     Israel Discount Bank of New York    January 11, 2002  \n",
       "554  AR  34248                   Delta Trust & Bank   September 7, 2001  \n",
       "555  IL  32646                Superior Federal, FSB       July 27, 2001  \n",
       "556  OH   6629                    North Valley Bank         May 3, 2001  \n",
       "557  NH  34264  Southern New Hampshire Bank & Trust    February 2, 2001  \n",
       "558  IL   3815              Banterra Bank of Marion   December 14, 2000  \n",
       "559  HI  21029                   Bank of the Orient    October 13, 2000  \n",
       "\n",
       "[560 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfIDjovpPLTN"
   },
   "source": [
    "#### Importing XML Files from the Web\n",
    "\n",
    "XML files are semi-structured, but you're at the mercy of the file creator. If every record has the same format it will be much easier, but practical applications often require a lot of custom code. Here is an example that includes a nice parser class: http://www.austintaylor.io/lxml/python/pandas/xml/dataframe/2016/07/08/convert-xml-to-pandas-dataframe/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W58nu1KsPLTN"
   },
   "source": [
    "#### Importing JSON Files from the Web\n",
    "\n",
    "Like XML, JSON files are semi-structured and may require work to capture the schema into a dataframe. Here is a simple example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfG7FTRrPLTO",
    "outputId": "c52ab6d9-5c67-4d17-a3fb-f148bd7dcc31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>integer</th>\n",
       "      <th>datetime</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-01-01 00:00:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-01-01 00:00:10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-01-01 00:00:11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>2015-01-01 00:00:12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    integer            datetime  category\n",
       "0         5 2015-01-01 00:00:00         0\n",
       "1         5 2015-01-01 00:00:01         0\n",
       "10        5 2015-01-01 00:00:10         0\n",
       "11        5 2015-01-01 00:00:11         0\n",
       "12        8 2015-01-01 00:00:12         0"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/data.json'\n",
    "\n",
    "# Load the first sheet of the JSON file into a data frame\n",
    "df = pd.read_json(url, orient = 'columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02GgleMQPLTR"
   },
   "source": [
    "## Part 2: Data Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SG4iZ2dcPLTR"
   },
   "source": [
    "Data munging is manipulating data to get it into a form that we can start running analyses on (which usually means getting the data into a DataFrame). Before we get to this stage, we may need to remove headers or footers, transpose columns to rows, split wide data tables into long ones, and so on. (Nb. Excel files can be particularly troublesome, because users can format their data in mixed, complex shapes.) Essentially, we need to follow Hadley Wickham's guidelines for tidy datasets (http://vita.had.co.nz/papers/tidy-data.html):\n",
    "\n",
    "The end goal of the cleaning data process:\n",
    "\n",
    "- each variable should be in one column\n",
    "- each observation should comprise one row\n",
    "- each type of observational unit should form one table\n",
    "- include key columns for linking multiple tables\n",
    "- the top row contains (sensible) variable names\n",
    "- in general, save data as one file per table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTWMfG9qPLTS"
   },
   "source": [
    "### Dataset Morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UncJF3aPLTT"
   },
   "source": [
    "Once we have our dataset in a DataFrame (or Series, if our data is only 1-dimensional), we can start examining its size and content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YSrlf0TPLTT"
   },
   "source": [
    "How many rows and columns are in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9mwKlaMPLTU",
    "outputId": "62498254-9bb8-47b0-9ac7-cbcec3cb7e71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17379, 17)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SywQpfhtPLTX"
   },
   "source": [
    "What are the column names in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUzgzxO1PLTX",
    "outputId": "2efde7d4-2ad3-4b91-930e-005240e4a283"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instant', 'dteday', 'season', 'yr', 'mnth', 'hr', 'holiday', 'weekday',\n",
       "       'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed',\n",
       "       'casual', 'registered', 'cnt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Fke7brePLTa"
   },
   "source": [
    "What are the data types of these columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w5gyfj7_PLTb",
    "outputId": "55e6bde5-4abb-4fd2-c452-8ec01833a52c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant         int64\n",
       "dteday         object\n",
       "season          int64\n",
       "yr              int64\n",
       "mnth            int64\n",
       "hr              int64\n",
       "holiday         int64\n",
       "weekday         int64\n",
       "workingday      int64\n",
       "weathersit      int64\n",
       "temp          float64\n",
       "atemp         float64\n",
       "hum           float64\n",
       "windspeed     float64\n",
       "casual          int64\n",
       "registered      int64\n",
       "cnt             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwenCqZHPLTe"
   },
   "source": [
    "What is the (row) index for this DataFrame?\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWsWoi3mPLTf",
    "outputId": "33db8e42-7cea-4d5f-a4a1-ead0a65de9b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=17379, step=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2323WWjYPLTh"
   },
   "source": [
    "https://www.dataquest.io/blog/python-json-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RcSvt7gbPLTi"
   },
   "source": [
    "## Slicing and Dicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnnPcHxyPLTi"
   },
   "source": [
    "It is often preferable to refer to DataFrame columns by name, but there is more than one way to do this. \n",
    "Do `bikes['season']` and `bikes[['season']]` give the same object? Demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Xdl6Tv0PLTi",
    "outputId": "f01b4556-8036-4107-f3fe-b9c6c7fefaff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.2879\n",
      "1    0.2727\n",
      "2    0.2727\n",
      "3    0.2879\n",
      "4    0.2879\n",
      "Name: atemp, dtype: float64\n",
      "<class 'pandas.core.series.Series'>\n",
      "    atemp\n",
      "0  0.2879\n",
      "1  0.2727\n",
      "2  0.2727\n",
      "3  0.2879\n",
      "4  0.2879\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "print(bikes['atemp'].head())\n",
    "print(type(bikes['atemp']))\n",
    "print(bikes[['atemp']].head())\n",
    "print(type(bikes[['atemp']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQQVBWOVPLTk"
   },
   "source": [
    "How would we use object notation to show the first 4 rows of `atemp`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sv1GwAEmPLTl",
    "outputId": "ad1912df-d79f-43c8-e720-a5e04f43420d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.2879\n",
      "1    0.2727\n",
      "2    0.2727\n",
      "3    0.2879\n",
      "Name: atemp, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "print(bikes.atemp[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaUySF3NPLTn"
   },
   "source": [
    "Algorithms that loop over multiple columns often access DataFrame columns by index. However, none of the following work (try them out by uncommenting / removing the \"#E: \" ): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDu33kKBPLTn",
    "outputId": "384b6db2-85ed-4104-9e26-f36f91c3591c"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([0], dtype='int64')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d5757f329026>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbikes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#E: bikes[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#E: bikes[0,0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#E: bikes[[0,0]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[1;32m-> 2934\u001b[1;33m                                                    raise_missing=True)\n\u001b[0m\u001b[0;32m   2935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[0;32m   1353\u001b[0m                           raise_missing}\n\u001b[1;32m-> 1354\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1355\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[0;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1244\u001b[0m                 raise KeyError(\n\u001b[0;32m   1245\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[1;32m-> 1246\u001b[1;33m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[0;32m   1247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([0], dtype='int64')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "bikes[[0]]\n",
    "#E: bikes[0]\n",
    "#E: bikes[0,0]\n",
    "#E: bikes[[0,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERnuRdHXPLTp"
   },
   "source": [
    "What is the correct way to access the 1st row of the DataFrame by its index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSxDxsjTPLTq",
    "outputId": "370d6f02-01a6-4919-9fe7-21d201885fcf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  "
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XkcrCXtPLTs"
   },
   "source": [
    "What is the correct way to access the 2nd column of the DataFrame by its index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUOw045oPLTt",
    "outputId": "7a732d4c-0ea1-4720-dd2b-2bbee73772a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2011-01-01\n",
       "1        2011-01-01\n",
       "2        2011-01-01\n",
       "3        2011-01-01\n",
       "4        2011-01-01\n",
       "5        2011-01-01\n",
       "6        2011-01-01\n",
       "7        2011-01-01\n",
       "8        2011-01-01\n",
       "9        2011-01-01\n",
       "10       2011-01-01\n",
       "11       2011-01-01\n",
       "12       2011-01-01\n",
       "13       2011-01-01\n",
       "14       2011-01-01\n",
       "15       2011-01-01\n",
       "16       2011-01-01\n",
       "17       2011-01-01\n",
       "18       2011-01-01\n",
       "19       2011-01-01\n",
       "20       2011-01-01\n",
       "21       2011-01-01\n",
       "22       2011-01-01\n",
       "23       2011-01-01\n",
       "24       2011-01-02\n",
       "25       2011-01-02\n",
       "26       2011-01-02\n",
       "27       2011-01-02\n",
       "28       2011-01-02\n",
       "29       2011-01-02\n",
       "            ...    \n",
       "17349    2012-12-30\n",
       "17350    2012-12-30\n",
       "17351    2012-12-30\n",
       "17352    2012-12-30\n",
       "17353    2012-12-30\n",
       "17354    2012-12-30\n",
       "17355    2012-12-31\n",
       "17356    2012-12-31\n",
       "17357    2012-12-31\n",
       "17358    2012-12-31\n",
       "17359    2012-12-31\n",
       "17360    2012-12-31\n",
       "17361    2012-12-31\n",
       "17362    2012-12-31\n",
       "17363    2012-12-31\n",
       "17364    2012-12-31\n",
       "17365    2012-12-31\n",
       "17366    2012-12-31\n",
       "17367    2012-12-31\n",
       "17368    2012-12-31\n",
       "17369    2012-12-31\n",
       "17370    2012-12-31\n",
       "17371    2012-12-31\n",
       "17372    2012-12-31\n",
       "17373    2012-12-31\n",
       "17374    2012-12-31\n",
       "17375    2012-12-31\n",
       "17376    2012-12-31\n",
       "17377    2012-12-31\n",
       "17378    2012-12-31\n",
       "Name: dteday, Length: 17379, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55q-NtPpPLTv"
   },
   "source": [
    "?.............................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tr7K0OqTPLTv"
   },
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93Im-qU6PLTw"
   },
   "source": [
    "What is the Pandas `isnull` function for? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcyiIEN2PLTw"
   },
   "source": [
    "?\n",
    "ANSWER: Detecting missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iER927QiPLTw"
   },
   "source": [
    "We can apply `isnull` to the `bikes` DataFrame to show the result for every element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g6ry8ujIPLTw",
    "outputId": "40f3c8fb-a21c-4e78-b118-881f6545b84f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant  dteday  season     yr   mnth     hr  holiday  weekday  workingday  \\\n",
       "0    False   False   False  False  False  False    False    False       False   \n",
       "1    False   False   False  False  False  False    False    False       False   \n",
       "2    False   False   False  False  False  False    False    False       False   \n",
       "3    False   False   False  False  False  False    False    False       False   \n",
       "4    False   False   False  False  False  False    False    False       False   \n",
       "\n",
       "   weathersit   temp  atemp    hum  windspeed  casual  registered    cnt  \n",
       "0       False  False  False  False      False   False       False  False  \n",
       "1       False  False  False  False      False   False       False  False  \n",
       "2       False  False  False  False      False   False       False  False  \n",
       "3       False  False  False  False      False   False       False  False  \n",
       "4       False  False  False  False      False   False       False  False  "
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.isnull().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyhMgJqEPLTx"
   },
   "source": [
    "However, we usually start at a higher level. How many nulls are in `bikes` altogether?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6a-0nVlPLTy",
    "outputId": "e9f5db5a-fd9e-4132-cac3-78210f838901"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes['windspeed'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5eCwHu8PLTz"
   },
   "source": [
    "If this result were nonzero we would next want to find out which columns contained nulls. How can this be done in one line of code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXq6AZ4WPLTz",
    "outputId": "d0b876b7-1796-4c86-ba23-12c59dac2d98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       0\n",
       "dteday        0\n",
       "season        0\n",
       "yr            0\n",
       "mnth          0\n",
       "hr            0\n",
       "holiday       0\n",
       "weekday       0\n",
       "workingday    0\n",
       "weathersit    0\n",
       "temp          0\n",
       "atemp         0\n",
       "hum           0\n",
       "windspeed     0\n",
       "casual        0\n",
       "registered    0\n",
       "cnt           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pI9jArWiPLT0"
   },
   "source": [
    "What is the Numpy object `nan` used for? (Write a descriptive answer.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUzpQqy7PLT1"
   },
   "source": [
    "?\n",
    "ANSWER: Marking a data point as invalid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCyh1WWYPLT1"
   },
   "source": [
    "Write (and verify) a function that performs scalar division with built-in handling of the edge case (i.e. return a value instead of just trapping the error):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAOyG-fsPLT1",
    "outputId": "26495e10-d177-48a2-d87b-b2f8efe1a569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "def divide(dividend, divisor):\n",
    "    if divisor == 0:\n",
    "        quotient = np.nan\n",
    "    else:\n",
    "        quotient = dividend / divisor\n",
    "    return (quotient)\n",
    "\n",
    "print(divide(1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1Y6isSRPLT2"
   },
   "source": [
    "Apply the Pandas `isna` function to the following data objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ziX8eiQ8PLT3",
    "outputId": "8e090a71-1ec0-42c7-a66c-f8b14f537c7d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3 nan\n"
     ]
    }
   ],
   "source": [
    "x = 2.3\n",
    "y = np.nan\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBZ2c8fWPLT4",
    "outputId": "6887e847-e314-4a46-c4ec-39eb6df83d6f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "print(pd.isna(x), pd.isna(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZvuDrLzPLT5",
    "outputId": "3d5049aa-12c3-4aec-d8da-03d8ac8e0304",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. nan  3.]\n",
      " [ 4.  5. nan]]\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[1, np.nan, 3], [4, 5, np.nan]])\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MYtR1zgdPLT6",
    "outputId": "72e4b826-755f-4976-d1fe-3e766df7c7a8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False  True False]\n",
      " [False False  True]]\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "print(pd.isna(array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CB0GwSMbPLT7"
   },
   "source": [
    "How is the pandas I/O parameter `na_values` used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2m6eO_gNPLT7"
   },
   "source": [
    "? ANSWER: For converting specially coded strings to NaN on input (e.g. \"###\", \"N/A\", \"NULL\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afj2-U8MPLT8"
   },
   "source": [
    "## Data Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fodaFKvVPLT8"
   },
   "source": [
    "### Counts\n",
    "\n",
    "When there are categorical variables in a dataset we will want to know how many possible values there are in each column. (Nb. If the dataset is a sample of a larger one, our sample may not capture all possible values of every categorical.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYUN8hK6PLT8"
   },
   "source": [
    "How many (different) seasons are in `bikes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNLe5AMoPLT8",
    "outputId": "b400b7ad-402c-4700-ae51-fe209abc11db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    4496\n",
       "2    4409\n",
       "1    4242\n",
       "4    4232\n",
       "Name: season, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes['season'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZXRRMW5PLT-"
   },
   "source": [
    "### Ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0tH5UQVPLT-"
   },
   "source": [
    "Print the range of the `instant`, `dteday`, and `windspeed` columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igQ895OFPLT-",
    "outputId": "abbba7c2-a09f-4b78-cc52-f7ce450d92f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instant: 1 to 17379\n",
      "dteday: 2011-01-01 to 2012-12-31\n",
      "windspeed: 0.0 to 0.8507\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "print('instant:', bikes['instant'].min(), 'to', bikes['instant'].max())\n",
    "print('dteday:', bikes['dteday'].min(), 'to', bikes['dteday'].max())\n",
    "print('windspeed:', bikes['windspeed'].min(), 'to', bikes['windspeed'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15F-MO1ZPLUA"
   },
   "source": [
    "Compute and print the overall minimum and maximum of the numeric data columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMYzYv73PLUA",
    "outputId": "4eab5295-b61e-4e5a-c31f-36d79cf0aa8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 17379.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes_min, bikes_max = (min(bikes.min(numeric_only=True)), \n",
    "                        max(bikes.max(numeric_only=True)))\n",
    "bikes_min, bikes_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClKUZFm-PLUB"
   },
   "source": [
    "### Quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCkNukA8PLUB"
   },
   "source": [
    "Pandas makes computing quantiles easy. This is how to get the median of a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_foH1BIUPLUB",
    "outputId": "9b0f3968-ee91-4d7b-e084-c1f724e1c309"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4848"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes['atemp'].quantile(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmB8btoxPLUC"
   },
   "source": [
    "Of course, the `quantiles` method can take a tuple as its argument. Compute the 10th, 25th, 50th, 75th, and 90th percentiles in one line of code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DfgKgsukPLUC",
    "outputId": "dc6f4470-c101-492f-9e37-81b0eaabc4d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10    0.2424\n",
       "0.25    0.3333\n",
       "0.50    0.4848\n",
       "0.75    0.6212\n",
       "0.90    0.6970\n",
       "Name: atemp, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes['atemp'].quantile((0.1, 0.25, 0.5, 0.75, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxALT_XzPLUE"
   },
   "source": [
    "### Cuts\n",
    "\n",
    "Sometimes we want to split the sample not by the quantiles of the distribution but by the range of the data. Let's take a closer look at `atemp`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGOJDFG0PLUE",
    "outputId": "6cff186f-53ab-4d5f-b56a-df019f32f8cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bikes['atemp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9NnQQ6cPLUG",
    "outputId": "f37ad07f-8475-46ee-c212-590d03118b13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>5552</td>\n",
       "      <td>2011-08-24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9443</th>\n",
       "      <td>9444</td>\n",
       "      <td>2012-02-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>18</td>\n",
       "      <td>252</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15105</th>\n",
       "      <td>15106</td>\n",
       "      <td>2012-09-26</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.2836</td>\n",
       "      <td>60</td>\n",
       "      <td>217</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9446</th>\n",
       "      <td>9447</td>\n",
       "      <td>2012-02-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>25</td>\n",
       "      <td>191</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9786</th>\n",
       "      <td>9787</td>\n",
       "      <td>2012-02-17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.4242</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.3284</td>\n",
       "      <td>36</td>\n",
       "      <td>429</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       instant      dteday  season  yr  mnth  hr  holiday  weekday  \\\n",
       "5551      5552  2011-08-24       3   0     8   5        0        3   \n",
       "9443      9444  2012-02-03       1   1     2   9        0        5   \n",
       "15105    15106  2012-09-26       4   1     9  14        0        3   \n",
       "9446      9447  2012-02-03       1   1     2  12        0        5   \n",
       "9786      9787  2012-02-17       1   1     2  17        0        5   \n",
       "\n",
       "       workingday  weathersit  temp   atemp   hum  windspeed  casual  \\\n",
       "5551            1           1  0.56  0.5303  0.73     0.1045       1   \n",
       "9443            1           1  0.24  0.2273  0.65     0.1940      18   \n",
       "15105           1           1  0.74  0.6667  0.48     0.2836      60   \n",
       "9446            1           1  0.34  0.3333  0.46     0.1343      25   \n",
       "9786            1           1  0.42  0.4242  0.32     0.3284      36   \n",
       "\n",
       "       registered  cnt  \n",
       "5551           26   27  \n",
       "9443          252  270  \n",
       "15105         217  277  \n",
       "9446          191  216  \n",
       "9786          429  465  "
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gw16ut-PLUI"
   },
   "source": [
    "Suppose we decide to sort these values into 4 bins of equal width, but we want to apply the resulting groups to the entire DataFrame. Basically, we need to add a row label that indcates which bin each sample belongs in. Let's call this label \"atemp_level\", and use the `cut` method to populate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IVCcNlg0PLUI"
   },
   "outputs": [],
   "source": [
    "atemp_level = pd.cut(bikes['atemp'], bins = 4)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoVc6rnAPLUI"
   },
   "source": [
    "What is `atemp_level`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkPpsPwKPLUJ",
    "outputId": "1b03fe43-92f6-4dd5-f4a6-82269d4478ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#ANSWER\n",
    "print(type(atemp_level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fz1-PYxHPLUK"
   },
   "source": [
    "Here is a random sample of `atemp_level`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evUQ8diZPLUK",
    "outputId": "d7503a94-c0f5-4050-9db7-fb533896106a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13956       (0.75, 1.0]\n",
       "9077     (-0.001, 0.25]\n",
       "15544       (0.5, 0.75]\n",
       "10389       (0.5, 0.75]\n",
       "1248        (0.25, 0.5]\n",
       "Name: atemp, dtype: category\n",
       "Categories (4, interval[float64]): [(-0.001, 0.25] < (0.25, 0.5] < (0.5, 0.75] < (0.75, 1.0]]"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atemp_level.sample(5)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9W8WadgCPLUL"
   },
   "source": [
    "So, by default, `cut` produces labels that indicate the bin boundaries for each element in the series it was applied to. Usually, we will specify labels that are appropriate to the discretisation we are applying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wZGCZG_PLUL",
    "outputId": "0a040c55-9abc-47e4-9243-d032031c33e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "964      mild\n",
       "1601     cool\n",
       "8387     mild\n",
       "12139    warm\n",
       "6244     warm\n",
       "Name: atemp, dtype: category\n",
       "Categories (4, object): [cool < mild < warm < hot]"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atemp_level = pd.cut(bikes['atemp'], bins = 4, labels = [\"cool\", \"mild\", \"warm\", \"hot\"])\n",
    "atemp_level.sample(5)          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12HEa-rUPLUM"
   },
   "source": [
    "Incorporate the new `atemp_level` column into the `bikes` DataFrame and use it to count the number of \"mild\" `atemp` entries in `season` 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DyanX8vHPLUN",
    "outputId": "98656fd5-ccbb-4f72-84f6-bdf922a08c41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1829"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ANSWER\n",
    "bikes['atemp_level'] = atemp_level\n",
    "bikes[(bikes.atemp_level == 'mild') & (bikes.season == 2)].season.count()  # Nb. could have used any column before count() in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGA2gUKQPLUO"
   },
   "source": [
    "*Nb. The `atemp_level` variable we created is what the R language calls a \"factor\". Pandas has introduced a new data type called \"category\" that is similar to R's factors.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21ZY_aGvPLUO"
   },
   "source": [
    "# Synthetic Data\n",
    "\n",
    "Sometimes we may want to generate test data, or we may need to initalise a series, matrix, or data frame for input to an algorithm. Numpy has several methods we can use for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovUUWNsoPLUO"
   },
   "source": [
    "Execute the following, then check the shape and content of each variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4xxsH4fPLUO"
   },
   "outputs": [],
   "source": [
    "# Creating arrays with initial values\n",
    "a = np.zeros((3))\n",
    "b = np.ones((1,3))\n",
    "c = np.random.randint(1,10,(2,3,4))   # randint(low, high, size)\n",
    "d = np.arange(4)\n",
    "e = np.array( [[1,2,3,4], [5,6,7,8]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmfN_aECPLUP"
   },
   "outputs": [],
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSei51LAWuo-"
   },
   "source": [
    "## Load Data\n",
    "\n",
    "Load rock.csv and clean the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "013qY06xWuo-"
   },
   "outputs": [],
   "source": [
    "# Load CSV File\n",
    "rock_csv = '../../../DATA/rock.csv'\n",
    "rock = pd.read_csv(rock_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmxGzkI_WupB"
   },
   "source": [
    "## Check Column Names\n",
    "\n",
    "Check column names and clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7my2gZLWupC",
    "outputId": "9eb14657-1602-4dba-8246-6412cfe8549b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Song Clean', 'ARTIST CLEAN', 'Release Year', 'COMBINED', 'First?',\n",
       "       'Year?', 'PlayCount', 'F*G'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check column names\n",
    "rock.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjnnUh0wWupF"
   },
   "source": [
    "Columns names are not uniform.\n",
    "\n",
    "    Uppercase, Lowercase > Lowercase\n",
    "    Space > _\n",
    "    ?, * > Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRFWr9xIWupH"
   },
   "outputs": [],
   "source": [
    "def clean_column_name(column_names):\n",
    "    clean_column_names = []\n",
    "    for c in column_names:\n",
    "        c = c.lower().replace(' ', '_')\n",
    "        c = c.lower().replace('*', '')\n",
    "        c = c.lower().replace('?', '')\n",
    "        clean_column_names.append(c)\n",
    "        \n",
    "    return clean_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VRCneLPWupO"
   },
   "outputs": [],
   "source": [
    "rock.columns = clean_column_name(rock.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wv46GtnxWupW"
   },
   "source": [
    "# Replace Null Values With 0\n",
    "\n",
    "Check 'release' column whether this column have any null value or not. Replace null value with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ylXlQKPKWupX",
    "outputId": "e7e9f5f5-24fa-4588-a22b-aef439cdf58d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_clean        0\n",
       "artist_clean      0\n",
       "release_year    577\n",
       "combined          0\n",
       "first             0\n",
       "year              0\n",
       "playcount         0\n",
       "fg                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check is there any nul values in any column\n",
    "rock.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rl4qq68kWupc"
   },
   "source": [
    "- release year got 577 null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jIz6ehXPWupd"
   },
   "outputs": [],
   "source": [
    "# Create a mask to find all rows with null values\n",
    "null_mask = rock['release_year'].isnull()\n",
    "rock.loc[null_mask, 'release_year'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0Odk3DvWuph",
    "outputId": "455c9f4c-53bc-40c9-e784-cc8227665c87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_clean      0\n",
       "artist_clean    0\n",
       "release_year    0\n",
       "combined        0\n",
       "first           0\n",
       "year            0\n",
       "playcount       0\n",
       "fg              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check is there any nul values in any column\n",
    "rock.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1x_A2f2Wupj"
   },
   "source": [
    "# Check Datatypes of Dataset\n",
    "\n",
    "Check datatypes of the dataset. Is there any column which should be int instead of object? Fix the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xZGh_uRWupk",
    "outputId": "3a141413-cf0f-4d7c-9c67-b6811929a4bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2230 entries, 0 to 2229\n",
      "Data columns (total 8 columns):\n",
      "song_clean      2230 non-null object\n",
      "artist_clean    2230 non-null object\n",
      "release_year    2230 non-null object\n",
      "combined        2230 non-null object\n",
      "first           2230 non-null int64\n",
      "year            2230 non-null int64\n",
      "playcount       2230 non-null int64\n",
      "fg              2230 non-null int64\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 139.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check datatypes\n",
    "rock.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQ_lq78xWupn"
   },
   "source": [
    "- release_year is object which should be integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiYZzf_dWupn",
    "outputId": "897ee7fd-e155-4c98-fd1a-8dccafe9c268"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                577\n",
       "1973             104\n",
       "1977              83\n",
       "1975              83\n",
       "1970              81\n",
       "1971              75\n",
       "1969              72\n",
       "1980              70\n",
       "1978              64\n",
       "1979              63\n",
       "1981              61\n",
       "1967              61\n",
       "1983              60\n",
       "1976              56\n",
       "1982              54\n",
       "1984              51\n",
       "1972              50\n",
       "1974              48\n",
       "1968              46\n",
       "1987              39\n",
       "1985              39\n",
       "1986              37\n",
       "1991              34\n",
       "1989              32\n",
       "1966              30\n",
       "1988              29\n",
       "1965              28\n",
       "1994              25\n",
       "1990              22\n",
       "1993              19\n",
       "1992              14\n",
       "1964              14\n",
       "1999              13\n",
       "1995              10\n",
       "1997               9\n",
       "1963               9\n",
       "1996               9\n",
       "2002               6\n",
       "1998               6\n",
       "2005               5\n",
       "2004               5\n",
       "2012               5\n",
       "2001               4\n",
       "2007               3\n",
       "2008               3\n",
       "1962               3\n",
       "2003               3\n",
       "2000               3\n",
       "2011               3\n",
       "2014               2\n",
       "2013               2\n",
       "1961               1\n",
       "1958               1\n",
       "1955               1\n",
       "1071               1\n",
       "SONGFACTS.COM      1\n",
       "2006               1\n",
       "Name: release_year, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chekc values of release_year\n",
    "\n",
    "rock['release_year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88N9-3RAWupr"
   },
   "source": [
    "- SONGFACTS.COM is not a valid release_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1EpWBj3SWupu"
   },
   "outputs": [],
   "source": [
    "# Create a mask to find all rows with SONGFACTS.COM\n",
    "song_facts_mask = rock['release_year'] == 'SONGFACTS.COM'\n",
    "rock.loc[song_facts_mask, 'release_year'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GR1062N7Wupw"
   },
   "outputs": [],
   "source": [
    "# Convert release year to numeric\n",
    "rock['release_year'] = pd.to_numeric(rock['release_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10b7mMVRWupy",
    "outputId": "c42c3e82-1436-494e-f1c0-bb4a3482bf87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_clean       object\n",
       "artist_clean     object\n",
       "release_year    float64\n",
       "combined         object\n",
       "first             int64\n",
       "year              int64\n",
       "playcount         int64\n",
       "fg                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types\n",
    "rock.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01XV7lTPWupz"
   },
   "source": [
    "# Check Min, Max of Each Column\n",
    "\n",
    "*   List item\n",
    "*   List item\n",
    "\n",
    "\n",
    "\n",
    "Is there any illogical value in any column? How can we fix that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtJfDfm5Wup0"
   },
   "outputs": [],
   "source": [
    "def check_min_max(df):\n",
    "    # Check min, max of each column\n",
    "    print(df.describe().T[['min', 'max']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kl1h1WcJWup1",
    "outputId": "43178f6d-06e6-482c-8ae3-0dfd19c7f885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              min     max\n",
      "release_year  0.0  2014.0\n",
      "first         1.0     1.0\n",
      "year          0.0     1.0\n",
      "playcount     0.0   142.0\n",
      "fg            0.0   142.0\n"
     ]
    }
   ],
   "source": [
    "check_min_max(rock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aS0KAwWKWup3"
   },
   "source": [
    "- Minimum Value of release year is 0, which is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eegPP172Wup3"
   },
   "outputs": [],
   "source": [
    "# Create a mask to find all rows with 0\n",
    "song_facts_mask = rock['release_year'] == 0\n",
    "rock.loc[song_facts_mask, 'release_year'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "60pDYX-eWup4",
    "outputId": "6e850301-e1a4-4042-c26f-1786beb66986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 min     max\n",
      "release_year  1071.0  2014.0\n",
      "first            1.0     1.0\n",
      "year             0.0     1.0\n",
      "playcount        0.0   142.0\n",
      "fg               0.0   142.0\n"
     ]
    }
   ],
   "source": [
    "check_min_max(rock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v--xPX6uWup5"
   },
   "source": [
    "*italicized text*- Still minimum value is 1071. It's very unlikely there were any rock song in that year!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXhpZRoDWup6"
   },
   "outputs": [],
   "source": [
    "# Create a mask to find all rows with 0\n",
    "song_facts_mask = rock['release_year'] == 1071\n",
    "rock.loc[song_facts_mask, 'release_year'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkJVdWfMWup7",
    "outputId": "8a6e0dbe-4431-45a8-c09e-e1c262a6b2ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 min     max\n",
      "release_year  1955.0  2014.0\n",
      "first            1.0     1.0\n",
      "year             0.0     1.0\n",
      "playcount        0.0   142.0\n",
      "fg               0.0   142.0\n"
     ]
    }
   ],
   "source": [
    "check_min_max(rock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIEg0kwiWup8"
   },
   "source": [
    "# Write Some Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjgKKTY1Wup9"
   },
   "source": [
    "## Write a function that will take a row of a DataFrame and print out the song, artist, and whether or not the release date is < 1970"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPflHa09Wup-",
    "outputId": "b69101ac-28c4-4ae6-e57e-2f1716acad0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_clean       object\n",
       "artist_clean     object\n",
       "release_year    float64\n",
       "combined         object\n",
       "first             int64\n",
       "year              int64\n",
       "playcount         int64\n",
       "fg                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtUu6LZXWup_"
   },
   "outputs": [],
   "source": [
    "def check_song(row):\n",
    "    print('Song: ', row['song_clean'])\n",
    "    print('Artist: ', row['artist_clean'])\n",
    "    print('Released before 1970: ', row['release_year'] < 1970)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzYLXjLyWuqC",
    "outputId": "c227c1c9-3a01-457c-a602-b17c92070a6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_clean                     Caught Up in You\n",
       "artist_clean                        .38 Special\n",
       "release_year                               1982\n",
       "combined        Caught Up in You by .38 Special\n",
       "first                                         1\n",
       "year                                          1\n",
       "playcount                                    82\n",
       "fg                                           82\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7muJKOxgWuqH",
    "outputId": "b385fcfe-a657-40ea-9379-1efe2dcc1767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song:  Caught Up in You\n",
      "Artist:  .38 Special\n",
      "Released before 1970:  False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check any row using index\n",
    "check_song(rock.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mj-zdybeWuqP",
    "outputId": "9a05c2c4-26df-4548-be4f-bb1d6c544f27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song:  Caught Up in You\n",
      "Artist:  .38 Special\n",
      "Released before 1970:  False\n",
      "\n",
      "\n",
      "Song:  Fantasy Girl\n",
      "Artist:  .38 Special\n",
      "Released before 1970:  False\n",
      "\n",
      "\n",
      "Song:  Hold On Loosely\n",
      "Artist:  .38 Special\n",
      "Released before 1970:  False\n",
      "\n",
      "\n",
      "Song:  Rockin' Into the Night\n",
      "Artist:  .38 Special\n",
      "Released before 1970:  False\n",
      "\n",
      "\n",
      "Song:  Art For Arts Sake\n",
      "Artist:  10cc\n",
      "Released before 1970:  False\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "2    None\n",
       "3    None\n",
       "4    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check first five rows\n",
    "rock.head(5).apply(check_song, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9Uws_-MWuqR"
   },
   "source": [
    "## Write a function that converts cells in a DataFrame to float and otherwise replaces them with np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bP__R2tDWuqS"
   },
   "outputs": [],
   "source": [
    "def convert_to_float(column):\n",
    "    column = pd.to_numeric(column, errors='coerce')\n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVCHKOjdWuqT"
   },
   "source": [
    "## Apply these functions to your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUgc9fTqWuqU",
    "outputId": "ffa2cb84-9cf5-4f30-c587-255d23951ca2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_clean</th>\n",
       "      <th>artist_clean</th>\n",
       "      <th>release_year</th>\n",
       "      <th>combined</th>\n",
       "      <th>first</th>\n",
       "      <th>year</th>\n",
       "      <th>playcount</th>\n",
       "      <th>fg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2230 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      song_clean  artist_clean  release_year  combined  first  year  \\\n",
       "0            NaN           NaN        1982.0       NaN      1     1   \n",
       "1            NaN           NaN           NaN       NaN      1     0   \n",
       "2            NaN           NaN        1981.0       NaN      1     1   \n",
       "3            NaN           NaN        1980.0       NaN      1     1   \n",
       "4            NaN           NaN        1975.0       NaN      1     1   \n",
       "5            NaN           NaN        2000.0       NaN      1     1   \n",
       "6            NaN           NaN        2000.0       NaN      1     1   \n",
       "7            NaN           NaN        2002.0       NaN      1     1   \n",
       "8            NaN           NaN        1992.0       NaN      1     1   \n",
       "9            NaN           NaN        1985.0       NaN      1     1   \n",
       "10           NaN           NaN           NaN       NaN      1     0   \n",
       "11           NaN           NaN        1980.0       NaN      1     1   \n",
       "12           NaN           NaN        1993.0       NaN      1     1   \n",
       "13           NaN           NaN           NaN       NaN      1     0   \n",
       "14           NaN           NaN        1976.0       NaN      1     1   \n",
       "15           NaN           NaN        1981.0       NaN      1     1   \n",
       "16           NaN           NaN           NaN       NaN      1     0   \n",
       "17           NaN           NaN        1995.0       NaN      1     1   \n",
       "18           NaN           NaN        1980.0       NaN      1     1   \n",
       "19           NaN           NaN        1980.0       NaN      1     1   \n",
       "20           NaN           NaN        1979.0       NaN      1     1   \n",
       "21           NaN           NaN        1975.0       NaN      1     1   \n",
       "22           NaN           NaN        1984.0       NaN      1     1   \n",
       "23           NaN           NaN        1977.0       NaN      1     1   \n",
       "24           NaN           NaN           NaN       NaN      1     0   \n",
       "25           NaN           NaN           NaN       NaN      1     0   \n",
       "26           NaN           NaN           NaN       NaN      1     0   \n",
       "27           NaN           NaN        1979.0       NaN      1     1   \n",
       "28           NaN           NaN        1980.0       NaN      1     1   \n",
       "29           NaN           NaN           NaN       NaN      1     0   \n",
       "...          ...           ...           ...       ...    ...   ...   \n",
       "2200         NaN           NaN        1983.0       NaN      1     1   \n",
       "2201         NaN           NaN        1971.0       NaN      1     1   \n",
       "2202         NaN           NaN        1971.0       NaN      1     1   \n",
       "2203         NaN           NaN           NaN       NaN      1     0   \n",
       "2204         NaN           NaN        1971.0       NaN      1     1   \n",
       "2205         NaN           NaN           NaN       NaN      1     0   \n",
       "2206         NaN           NaN           NaN       NaN      1     0   \n",
       "2207         NaN           NaN        1968.0       NaN      1     1   \n",
       "2208         NaN           NaN           NaN       NaN      1     0   \n",
       "2209         NaN           NaN        1976.0       NaN      1     1   \n",
       "2210         NaN           NaN        1973.0       NaN      1     1   \n",
       "2211         NaN           NaN        1980.0       NaN      1     1   \n",
       "2212         NaN           NaN        1983.0       NaN      1     1   \n",
       "2213         NaN           NaN        1983.0       NaN      1     1   \n",
       "2214         NaN           NaN        1975.0       NaN      1     1   \n",
       "2215         NaN           NaN           NaN       NaN      1     0   \n",
       "2216         NaN           NaN           NaN       NaN      1     0   \n",
       "2217         NaN           NaN        1973.0       NaN      1     1   \n",
       "2218         NaN           NaN           NaN       NaN      1     0   \n",
       "2219         NaN           NaN        1973.0       NaN      1     1   \n",
       "2220         NaN           NaN        1983.0       NaN      1     1   \n",
       "2221         NaN           NaN           NaN       NaN      1     0   \n",
       "2222         NaN           NaN           NaN       NaN      1     0   \n",
       "2223         NaN           NaN        1981.0       NaN      1     1   \n",
       "2224         NaN           NaN        1983.0       NaN      1     1   \n",
       "2225         NaN           NaN           NaN       NaN      1     0   \n",
       "2226         NaN           NaN        1981.0       NaN      1     1   \n",
       "2227         NaN           NaN        1975.0       NaN      1     1   \n",
       "2228         NaN           NaN        1983.0       NaN      1     1   \n",
       "2229         NaN           NaN        1973.0       NaN      1     1   \n",
       "\n",
       "      playcount   fg  \n",
       "0            82   82  \n",
       "1             3    0  \n",
       "2            85   85  \n",
       "3            18   18  \n",
       "4             1    1  \n",
       "5            13   13  \n",
       "6             1    1  \n",
       "7             6    6  \n",
       "8             3    3  \n",
       "9             1    1  \n",
       "10            1    0  \n",
       "11           97   97  \n",
       "12            6    6  \n",
       "13            5    0  \n",
       "14           85   85  \n",
       "15           46   46  \n",
       "16           24    0  \n",
       "17            1    1  \n",
       "18           39   39  \n",
       "19           74   74  \n",
       "20           92   92  \n",
       "21           39   39  \n",
       "22            1    1  \n",
       "23            3    3  \n",
       "24            4    0  \n",
       "25            2    0  \n",
       "26           20    0  \n",
       "27            1    1  \n",
       "28           21   21  \n",
       "29           45    0  \n",
       "...         ...  ...  \n",
       "2200         81   81  \n",
       "2201         44   44  \n",
       "2202          1    1  \n",
       "2203          5    0  \n",
       "2204          1    1  \n",
       "2205          2    0  \n",
       "2206          1    0  \n",
       "2207         14   14  \n",
       "2208          1    0  \n",
       "2209          1    1  \n",
       "2210          8    8  \n",
       "2211         34   34  \n",
       "2212         86   86  \n",
       "2213         29   29  \n",
       "2214          2    2  \n",
       "2215         16    0  \n",
       "2216         10    0  \n",
       "2217          6    6  \n",
       "2218          2    0  \n",
       "2219        111  111  \n",
       "2220        121  121  \n",
       "2221          1    0  \n",
       "2222         14    0  \n",
       "2223          5    5  \n",
       "2224        120  120  \n",
       "2225          1    0  \n",
       "2226         32   32  \n",
       "2227        109  109  \n",
       "2228          1    1  \n",
       "2229          2    2  \n",
       "\n",
       "[2230 rows x 8 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock.apply(convert_to_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H53xn1YzWuqW"
   },
   "source": [
    "Describe the new float-only DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KiBKFpE-WuqW",
    "outputId": "4c84b43c-b7ba-4759-8555-83150ae5e81b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>release_year</th>\n",
       "      <td>1651.0</td>\n",
       "      <td>1978.569352</td>\n",
       "      <td>9.309780</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2230.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2230.0</td>\n",
       "      <td>0.741256</td>\n",
       "      <td>0.438043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playcount</th>\n",
       "      <td>2230.0</td>\n",
       "      <td>16.872646</td>\n",
       "      <td>25.302972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fg</th>\n",
       "      <td>2230.0</td>\n",
       "      <td>15.048430</td>\n",
       "      <td>25.288366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count         mean        std     min     25%     50%     75%  \\\n",
       "release_year  1651.0  1978.569352   9.309780  1955.0  1971.0  1977.0  1984.0   \n",
       "first         2230.0     1.000000   0.000000     1.0     1.0     1.0     1.0   \n",
       "year          2230.0     0.741256   0.438043     0.0     0.0     1.0     1.0   \n",
       "playcount     2230.0    16.872646  25.302972     0.0     1.0     4.0    21.0   \n",
       "fg            2230.0    15.048430  25.288366     0.0     0.0     3.0    18.0   \n",
       "\n",
       "                 max  \n",
       "release_year  2014.0  \n",
       "first            1.0  \n",
       "year             1.0  \n",
       "playcount      142.0  \n",
       "fg             142.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe Dataframe. All columns are float.\n",
    "rock.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hj8GdoOXC-Lu"
   },
   "source": [
    "\n",
    "\n",
    "> \n",
    ">\n",
    ">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlasiTKgDGdA"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2021 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LCfcsBYyPLS7",
    "V9XLZahIPLTF",
    "4gnyWmX1PLTG",
    "cLZSU6EsPLTJ",
    "qfIDjovpPLTN",
    "W58nu1KsPLTN",
    "WTWMfG9qPLTS",
    "fodaFKvVPLT8",
    "6ZXRRMW5PLT-",
    "ClKUZFm-PLUB",
    "HxALT_XzPLUE"
   ],
   "name": "IOD_Lab 3.1.1 - answers.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
