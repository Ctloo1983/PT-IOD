{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AAUCnGGAN81w"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RjxxRZ83N81y"
   },
   "source": [
    "# Lab 3.1.2 \n",
    "# *Exploring Data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f5i73AfjN810"
   },
   "source": [
    "## Part 1: Continuous and Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vm1g3nFjN813"
   },
   "source": [
    "When we explore a dataset we usually produce textual and graphical output together, starting with a high-level overview of the data and gradually drilling down into the individual features and relationships between them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bXolkmZTN814"
   },
   "source": [
    "Our most important libraries for this task are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1ZshShAN816"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "\n",
    "# Cause plots to be displayed in the notebook:\n",
    "%pylab inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S4xwjz_2Vkuc"
   },
   "outputs": [],
   "source": [
    "# Override default figure sizing:\n",
    "pylab.rcParams['figure.figsize'] = (10, 6)\n",
    "sns.set(color_codes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hLwrqPHXN82B"
   },
   "source": [
    "## Data Profiling\n",
    "\n",
    "We actually start profiling the data when we first load it and check for input errors, as in the last lab. Once we have a DataFrame we can work with, however, things start getting more interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SeWXc7c-N82C"
   },
   "source": [
    "**Load the file \"bikeshare.csv\" into a DataFrame named `bikes`, and check that it was loaded properly:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mxDB-sxHN82D"
   },
   "outputs": [],
   "source": [
    "#ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Noi0QDuQN82H"
   },
   "source": [
    "We may want our program to capture particular features of the dataset into variables, but if we just want to get a feel for the data it is easier to use a higher-level Pandas method like `describe()`:\n",
    "\n",
    "**Use `describe` to get the description of datasets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6z-Gth5HN82I"
   },
   "outputs": [],
   "source": [
    "#ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hYx4OyNiN82N"
   },
   "source": [
    "### Continuous Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQgv9YU6N82P"
   },
   "source": [
    "We may have to do a lot of work before we can produce presentable graphics, but we can start creating simple visualisations as soon as we have a DataFrame. \n",
    "\n",
    "We usually start charting variables one-by-one (although when several have the same range it may be preferable to overlay them, using a different colour or symbol for each)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JOrr95mNN82U"
   },
   "source": [
    "**Use the `scatter` method of Pandas to create a scatter plot of `windspeed`, `temp`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZoY0XTgN82U"
   },
   "outputs": [],
   "source": [
    "#ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pAftUjteN82W"
   },
   "source": [
    "**The `scatter` method has various parameters for controlling the appearance of the chart. Experiment with `s` , `linewidths`, and `alpha` below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l7w1tRLxN82X"
   },
   "outputs": [],
   "source": [
    "#ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2YvEtRe6N82Z"
   },
   "source": [
    "The scatterplot shows us the raw data. Our next step is usually to see how it is distributed, which is what the histogram is for: \n",
    "\n",
    "> A histogram is used for continuous data, where the bins represent ranges of data, while a bar chart is a plot of categorical variables. <sup>[1](#histfootnote)</sup>\n",
    "\n",
    "- **Identify continuous varaibles**\n",
    "- **Create histogram for those variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I7xkrKxEN82Z",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q2Sd9MPrN82b"
   },
   "source": [
    "What do the horizontal and vertical axes represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wQO19BD6N82c"
   },
   "source": [
    "#### ANSWER: \n",
    "    horiz = magnitude of `atemp`, apparently normalised to [0, 1], discretised into bins of width 0.1; \n",
    "    vertical = counts of samples in each bin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dwIZmUIhN82c"
   },
   "source": [
    "*NOTE: Samples in a given bin are greater than the axis value of its left side and less than or equal to the axis value of its right side. (The left-most bin is an exception: it represents greater than or equal to.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FllLePJIN82d"
   },
   "source": [
    "The box-and-whisker plot provides a compact view of the major percentiles of the distribution:\n",
    "\n",
    "**Make a box and whisker plot for the column ``atemp``.**  \n",
    "\n",
    "> The box extends from the lower to\n",
    "upper quartile values of the data, with a line at the median. The whiskers extend from the box to show the range of the data.  Flier points are those past the end of the whiskers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ns0i_m7-N82d"
   },
   "outputs": [],
   "source": [
    "#ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "quOrQERhN82f"
   },
   "source": [
    "This kind of plot really shines when we want to show several distributions at once (as long as they have compatible ranges). \n",
    "\n",
    "**Plot `atemp` and `windspeed` together. Change labels accordingly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbXdkED6N82f"
   },
   "outputs": [],
   "source": [
    "#ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a79ua1wHN82h"
   },
   "source": [
    "### Classified Data\n",
    "\n",
    "Samples may represent different classes according to one or more categorical variables. Sometimes our goal is to discover these classes, or to train a classification model from samples that have been manually classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMKqnzwYN82h"
   },
   "source": [
    "Here, the famous \"Iris\" dataset gets loaded from the UCI repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NYa-YgD3N82i"
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "# get Iris dataset from UCI Machine Learning Repository:\n",
    "url = \"http://goo.gl/HppjFh\" \n",
    "raw_data = urllib.request.urlopen(url)\n",
    "\n",
    "# load the CSV file:\n",
    "iris_data = pd.read_csv(raw_data, delimiter = \",\", \n",
    "                        names = ('sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g54OHp8tN82j"
   },
   "source": [
    "Note that the column names were overridden by the `names` argument of the Pandas `read.csv` method. This requires prior knowledge of the dataset, which we would normally get from a data dictionary (although sometimes we just have to figure it out for ourselves)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WkrDQM5rN82k"
   },
   "source": [
    "**Print the first few rows of this DataFrame:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r_OQLa_nN82l"
   },
   "outputs": [],
   "source": [
    "#ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqcCuzmhN82n"
   },
   "source": [
    "In this dataset, `species` has several possible values (representing the classes of the samples).\n",
    "\n",
    "**Find out distinct number of `species` and number of sample for each `species` in this dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yow5oelDN82o"
   },
   "outputs": [],
   "source": [
    "#ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RyB0OzQtN82q"
   },
   "source": [
    "We often need to capture the number of classes in code. We can do this with a variation on the above. Try this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h5WyByseN82r"
   },
   "outputs": [],
   "source": [
    "#ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kO-KGbACN82s"
   },
   "source": [
    "We often need to calculate aggregate values within subgroups of the dataset. The Pandas DataFrame method for this is `groupby`. \n",
    "\n",
    "**Apply the `groupby` method to get `mean` of `sepal_length` and `sepal_width` for the above dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dqAwiRb-N82t"
   },
   "outputs": [],
   "source": [
    "#ANSWER "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AbtlYwS4N82w"
   },
   "source": [
    "The Pandas `plot` method provides a quick way to produce a scatter plot.\n",
    "\n",
    "**Draw a Scatterplot showing sepal width and length using the Pandas `plot` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udAp87JGN82w"
   },
   "outputs": [],
   "source": [
    "#ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hnkVXr8hVkvg"
   },
   "source": [
    "**Draw a Barplot showing sepal width and length using the Pandas plot method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9uaIXHPzVkvh"
   },
   "outputs": [],
   "source": [
    "#ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Il80iAntN820"
   },
   "source": [
    "Draw a Scatterplot showing sepal width and length using the Pandas plot method.\n",
    "\n",
    "**[BONUS] Set `title`, `xlabel`, `ylabel` to the plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddF-FxrvN820"
   },
   "outputs": [],
   "source": [
    "#ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WPabGs1QN822"
   },
   "source": [
    "In this dataset we have also `petal_width`, `petal_length`. \n",
    "\n",
    "**Try to draw Scatterplot using these variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-rqQZSECN822"
   },
   "outputs": [],
   "source": [
    "#ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahhvXPe-N824"
   },
   "source": [
    "In this case, we already have different species, so we can colour the points accordingly. This is easy to do using the Seaborn library. Try using `lmplot` of seaborn library and use the parameter `hue` and `fit_reg = False`.\n",
    "\n",
    "**Draw a Scatterplot showing sepal width and length.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nO0c7l4IN824"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# Draw a Scatterplot showing sepal width and length:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ojVPLL3HVkv5"
   },
   "source": [
    "**[BONUS] Draw a Scatterplot showing sepal width and length. Without using seaborn.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nSpL2RSNVkv5"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lt13452uN825"
   },
   "source": [
    "To find out why this function is called `lmplot`, try it again with `fit_reg` = True:\n",
    "\n",
    "**Draw a Scatterplot showing sepal width and length:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gzauY2s_N825"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "# Draw a Scatterplot showing sepal width and length:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vh0kS5nXN826"
   },
   "source": [
    "The Seaborn `jointplot` function charts a correlation along with both distributions:\n",
    "\n",
    "**Draw a jointplot showing sepal width and length:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpGNJl_tN826"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C9DArDT8N828"
   },
   "source": [
    "When we want to see all the correlations at once, we can use `pairplot`:\n",
    "\n",
    "**Draw a `pairplot` of the dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ldqq3tigN829"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ci8lh0g7N82-"
   },
   "source": [
    "And, if the classes are known, we can apply colour using the `hue` parameter. Try this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OzuFvX9oN82-"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "50PIOUynN83A"
   },
   "source": [
    "Note that this gave us class-based distributions instead of an overall histogram, as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uoDpxc8UN83A"
   },
   "source": [
    "When we want to see numerical values of the correlations, the Pandas `corr` method provides a table of pair-wise correlations between the features in the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBYxqp-tN83B"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfztaHjTN83C"
   },
   "source": [
    "### High-Level Data Profiling Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rwds1QxPN83D"
   },
   "source": [
    "We need to master the basic data profiling functions because we will by using them frequently, for exploring data and answering ad hoc questions. In a production solution, we may need to incorporate specific data profiling code into our script so that we can automate data cleaning. However, when we just want to examine the data interactively before we start modelling, it is easier to use a high-level library like the following:\n",
    "\n",
    "> pip install pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "byalhXAiN83D"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "import pandas_profiling\n",
    "df = pd.read_csv(\"Meteorite_Landings.csv\", parse_dates = ['year'], encoding = 'UTF-8')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8VGuOIerVkwQ"
   },
   "source": [
    "Use `ProfileReport` of `pandas_profiling` to get the overview of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MBnnFN5HVkwR"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZADm2k8fN83F"
   },
   "source": [
    "For **HOMEWORK**: check out the `pydqc` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SbB5JVvKN83F"
   },
   "source": [
    "## Part 2: Time Series and Geospatial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V7qZWYezN83F"
   },
   "source": [
    "## Time Series\n",
    "\n",
    "A time series is basically a series or a data frame with a time-based index column. Working with time series introduces a lot of challenges and possibilities, but most tasks are catered for by the standard libraries in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3_aTqRxQN83G"
   },
   "source": [
    "Here is a history of air passenger counts by month, loaded into an ordinary DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mx13dmBNN83G"
   },
   "outputs": [],
   "source": [
    "airpass = pd.read_csv('AirPassengers.csv')\n",
    "airpass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "luUUHoIgN83H"
   },
   "outputs": [],
   "source": [
    "airpass.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XcIm7hAdN83I"
   },
   "source": [
    "Before going any further, the `TravelDate` column needs to be converted to the `datetime` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ex_OLiaVkwd"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qrTCKoQ4Vkwg"
   },
   "source": [
    "Set `TravelDate` as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvUCGd5iVkwh"
   },
   "outputs": [],
   "source": [
    "# ANSWER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mPIL1apbN83L"
   },
   "source": [
    "Now, Pandas knows that the first column of this DataFrame is a datetime index, so it only shows one column of data:\n",
    "\n",
    "Use `head` to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KAT1vFCUN83L"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vTxTzLBmN83M"
   },
   "source": [
    "Here's how to see the values of the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xy6SrwyoVkwl"
   },
   "outputs": [],
   "source": [
    "airpass.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iT5tn5ciN83N"
   },
   "source": [
    "If we had multiple data columns but we only wanted to work with a time series of one of them, we could pull that column into a 1D time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LNtFR7leN83N"
   },
   "outputs": [],
   "source": [
    "ts = airpass['Passengers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRlNSzcRN83P"
   },
   "source": [
    "We use the datetime index exactly like a row number index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "unJk--JsN83P"
   },
   "outputs": [],
   "source": [
    "print(ts['1949-01-01'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zvk2M_eMN83R"
   },
   "source": [
    "Or, we can refer to the row by its datetime equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GDb2bVvjN83R"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "print(ts[datetime(1949,1,1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHgJzsjNN83S"
   },
   "source": [
    "Happily, Pandas makes it easy to slice data at a courser grain. We can refer to a whole year of data by omitting the month and day form the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r5lSHnl6N83T"
   },
   "outputs": [],
   "source": [
    "print(ts['1949'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8nJxb0VCN83U"
   },
   "source": [
    "The most basic way to plot a time series is to let Pandas apply the default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-XlTUbQ4N83U"
   },
   "outputs": [],
   "source": [
    "ts.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UKQTTT6XN83V"
   },
   "source": [
    "## Geospatial Data\n",
    "\n",
    "Geospatial data is map-based (although what constitutes a \"map\" can go beyond the familiar). Ultimately, geographic data  occurs either in bitmap (raster) form or vector (resizeable polygons). It is not unusual for the two kinds of data to be used together.\n",
    "\n",
    "Because borders are often complex, following river courses, mountain ranges, and so on, the files that describe their geometries can be large. To reduce file sizes and image rendering times, we prefer to work with polygons that are no more detailed than the maximum resolution we need for our task. For this reason, geospatial files are often available at several different resolutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XYrkKzhXN83W"
   },
   "source": [
    "There are several popular options for working with maps in Python. We will use folium for its breadth and its use of open-source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b5WBGddFN83W"
   },
   "outputs": [],
   "source": [
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrYHSpI_Vkw9"
   },
   "outputs": [],
   "source": [
    "# Read SF Incidents data\n",
    "crime_csv = 'SFPD_Incidents_-_Current_Year__2015_.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DySTio-bVkw_"
   },
   "source": [
    "Convert `Date` Column to DateTime and set as index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-Cq0NPuVkw_"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ePYg9SyOVkxB"
   },
   "source": [
    "Draw a timeseries plot to visualize number of crimes for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zxaimc4vVkxB"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZUdihgH5VkxC"
   },
   "source": [
    "Using folium we can easily create a map. As it's SF data, by default we are using SF location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DYxExw9vVkxE"
   },
   "outputs": [],
   "source": [
    "def generateBaseMap(default_location=[37.76, -122.45], default_zoom_start=12):\n",
    "    '''\n",
    "    Create a base map\n",
    "    '''\n",
    "    base_map = folium.Map(\n",
    "        location = default_location\n",
    "        , control_scale = True\n",
    "        , zoom_start = default_zoom_start\n",
    "    )\n",
    "    \n",
    "    return base_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BhlQlSe2VkxF"
   },
   "outputs": [],
   "source": [
    "base_map = generateBaseMap(default_location=[37.76, -122.45])\n",
    "display(base_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yoCDQtgVVkxJ"
   },
   "source": [
    "Add a marker in the map using `Folium.Marker` for first 100 rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10J4Ob78VkxK"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4zpVDMb8VkxM"
   },
   "source": [
    "Add a cricle in the map using `Folium Circle` for first 100 rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "80zcdJJWVkxN"
   },
   "outputs": [],
   "source": [
    "# ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "--3r488OVkxP"
   },
   "source": [
    "[BONUS] Create a heatmap of the incident happened in SF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zc0Cpb2dVkxQ"
   },
   "source": [
    "**HOMEWORK** Explore Folium as mush as you can.\n",
    "\n",
    "**HOMEWORK** Explore GeoPandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MIVTghMcN83c"
   },
   "source": [
    "# More Resources\n",
    "\n",
    "<a name=\"histfootnote\">1</a>: [Histogram](https://en.wikipedia.org/wiki/Histogram)\n",
    "\n",
    "The matplotlib users' guide is at http://pageperso.lif.univ-mrs.fr/~francois.denis/IAAM1/Matplotlib.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nVVwCRLHN83c"
   },
   "source": [
    "For visualisation ideas and code see https://python-graph-gallery.com/:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TNSxyyomN83d"
   },
   "outputs": [],
   "source": [
    "# GeoPandas\n",
    "\n",
    "> The goal of GeoPandas is to make working with geospatial data in python easier. It combines the capabilities of pandas and shapely, providing geospatial operations in pandas and a high-level interface to multiple geometries to shapely. GeoPandas enables you to easily do operations in python that would otherwise require a spatial database such as PostGIS.\n",
    "\n",
    "[GeoPandas 0.4.0](http://geopandas.org/index.html#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MlasiTKgDGdA"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > Â© 2021 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "a79ua1wHN82h",
    "FfztaHjTN83C"
   ],
   "name": "DSIA Lab 3.1.2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
